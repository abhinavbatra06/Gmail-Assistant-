{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab12c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import openai\n",
    "import numpy as np\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26919ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 3 messages from nyu536@nyu.edu\n",
      "==================================================\n",
      "From: NYU Center for Data Science <nyu536@nyu.edu>\n",
      "Date: Tue, 30 Sep 2025 14:59:17 -0000\n",
      "Subject: CDS Weekly | Volume 6, Issue 5\n",
      "Body:\n",
      "NYU\n",
      "\n",
      "\n",
      "\n",
      "### CDS WEEKLY | VOLUME 6, ISSUE 5 | SEPTEMBER 30, 2025\n",
      "\n",
      "\n",
      "\n",
      "Important Dates & Reminders:\n",
      "\n",
      "  * Post-Completion OPT Guidelines for International Students:\n",
      "\n",
      "    *\n",
      "Information and instructions on theÂ OPTÂ process (https://t.e2ma.net/click/5estrh/dt03qtsf/9t26dz). Please note that for t...\n",
      "\n",
      "==================================================\n",
      "From: NYU Center for Data Science <nyu536@nyu.edu>\n",
      "Date: Tue, 23 Sep 2025 14:30:49 -0000\n",
      "Subject: CDS Weekly | Volume 6, Issue 4\n",
      "Body:\n",
      "NYU\n",
      "\n",
      "\n",
      "\n",
      "### CDS WEEKLY | VOLUME 6, ISSUE 4 | SEPTEMBER 23, 2025\n",
      "\n",
      "\n",
      "\n",
      "Important Dates & Reminders:\n",
      "\n",
      "  * Post-Completion OPT Guidelines for International Students:\n",
      "\n",
      "    *\n",
      "Information and instructions on theÂ OPTÂ process (https://t.e2ma.net/click/1n8crh/dt03qtsf/9l0jcz). Please note that for t...\n",
      "\n",
      "==================================================\n",
      "From: NYU Center for Data Science <nyu536@nyu.edu>\n",
      "Date: Tue, 16 Sep 2025 14:25:51 -0000\n",
      "Subject: CDS Weekly | Volume 6, Issue 1\n",
      "Body:\n",
      "NYU\n",
      "\n",
      "\n",
      "\n",
      "### CDS WEEKLY | VOLUME 6, ISSUE 3 | SEPTEMBER 16, 2025\n",
      "\n",
      "\n",
      "\n",
      "Important Dates & Reminders:\n",
      "\n",
      "  * DS-GA 1009/CPT Guidelines for CDS Graduate Students:\n",
      "\n",
      "    *\n",
      "Internship Course andÂ CPTÂ Guidelines (https://t.e2ma.net/click/dhn1qh/dt03qtsf/95zobz). At the latest, the completed package of...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os.path\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "def get_gmail_service():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('creds.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "def fetch_emails_from_senders(senders, max_per_sender=20):\n",
    "    \"\"\"Fetch emails from a list of senders (max n per sender).\"\"\"\n",
    "    service = get_gmail_service()\n",
    "    all_emails = []\n",
    "\n",
    "    for sender in senders:\n",
    "        query = f'from:{sender}'\n",
    "        results = service.users().messages().list(userId='me', q=query, maxResults=max_per_sender).execute()\n",
    "        messages = results.get('messages', [])\n",
    "        print(f\"Fetched {len(messages)} messages from {sender}\")\n",
    "\n",
    "        for msg in messages:\n",
    "            txt = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
    "            payload = txt['payload']\n",
    "            headers = payload.get(\"headers\")\n",
    "\n",
    "            subject, from_email, date = \"\", \"\", \"\"\n",
    "            for d in headers:\n",
    "                if d['name'] == 'Subject': subject = d['value']\n",
    "                if d['name'] == 'From': from_email = d['value']\n",
    "                if d['name'] == 'Date': date = d['value']\n",
    "\n",
    "            body = \"\"\n",
    "            if 'parts' in payload:\n",
    "                for part in payload['parts']:\n",
    "                    if part['mimeType'] == 'text/plain':\n",
    "                        data = part['body'].get('data')\n",
    "                        if data:\n",
    "                            body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "                    elif part['mimeType'] == 'text/html' and not body:\n",
    "                        data = part['body'].get('data')\n",
    "                        if data:\n",
    "                            html = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "                            body = BeautifulSoup(html, \"html.parser\").get_text()\n",
    "            else:\n",
    "                data = payload['body'].get('data')\n",
    "                if data:\n",
    "                    body = base64.urlsafe_b64decode(data).decode('utf-8')\n",
    "\n",
    "            all_emails.append({\n",
    "                \"id\": msg['id'],\n",
    "                \"from\": from_email,\n",
    "                \"subject\": subject,\n",
    "                \"date\": date,\n",
    "                \"body\": body.strip()\n",
    "            })\n",
    "\n",
    "    return all_emails\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f87521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import openai\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "# Load API key from env\n",
    "openai.api_key = os.getenv(\"api_key\")\n",
    "\n",
    "# ---- 1. Chunking ----\n",
    "def chunk_text(text, max_tokens=300, overlap=50):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = enc.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + max_tokens, len(tokens))\n",
    "        chunk = enc.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n",
    "\n",
    "# ---- 2. Embedding ----\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    resp = openai.Embedding.create(model=model, input=text)\n",
    "    return np.array(resp['data'][0]['embedding'], dtype=np.float32)\n",
    "\n",
    "# ---- 3. Build Index ----\n",
    "def build_faiss_index(emails):\n",
    "    dim = 1536  # embedding size for text-embedding-3-small\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    metadata = []\n",
    "    vectors = []\n",
    "\n",
    "    for e in emails:\n",
    "        chunks = chunk_text(e[\"body\"])\n",
    "        for i, ch in enumerate(chunks):\n",
    "            emb = get_embedding(ch)\n",
    "            vectors.append(emb)\n",
    "            metadata.append({\n",
    "                \"id\": f'{e[\"id\"]}_chunk{i}',\n",
    "                \"from\": e[\"from\"],\n",
    "                \"subject\": e[\"subject\"],\n",
    "                \"date\": e[\"date\"],\n",
    "                \"text\": ch\n",
    "            })\n",
    "\n",
    "    vectors = np.vstack(vectors)\n",
    "    index.add(vectors)\n",
    "    return index, metadata\n",
    "\n",
    "# ---- 4. Search ----\n",
    "def search_emails(query, index, metadata, k=3):\n",
    "    q_emb = get_embedding(query)\n",
    "    D, I = index.search(np.array([q_emb]), k)\n",
    "    results = [metadata[i] for i in I[0]]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8df23e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 5 messages from nyu536@nyu.edu\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m emails \u001b[38;5;241m=\u001b[39m fetch_emails_from_senders(senders, max_per_sender\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Build index\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m index, metadata \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_faiss_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43memails\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Ask a query\u001b[39;00m\n\u001b[0;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid John confirm the meeting time?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[13], line 38\u001b[0m, in \u001b[0;36mbuild_faiss_index\u001b[1;34m(emails)\u001b[0m\n\u001b[0;32m     36\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_text(e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[1;32m---> 38\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     vectors\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[0;32m     40\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chunk\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m: e[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: ch\n\u001b[0;32m     46\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_embedding\u001b[39m(text, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 25\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Python Install\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    senders = [\"nyu536@nyu.edu\"]\n",
    "    emails = fetch_emails_from_senders(senders, max_per_sender=10)\n",
    "\n",
    "    # Build index\n",
    "    index, metadata = build_faiss_index(emails)\n",
    "\n",
    "    # Ask a query\n",
    "    query = \"Did John confirm the meeting time?\"\n",
    "    results = search_emails(query, index, metadata, k=3)\n",
    "\n",
    "    print(\"\\nðŸ”Ž Retrieved Relevant Chunks:\\n\")\n",
    "    for r in results:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"From: {r['from']}\")\n",
    "        print(f\"Subject: {r['subject']}\")\n",
    "        print(f\"Date: {r['date']}\")\n",
    "        print(f\"Text: {r['text'][:300]}...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
