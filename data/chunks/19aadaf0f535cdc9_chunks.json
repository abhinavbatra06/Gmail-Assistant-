{
  "message_id": "19aadaf0f535cdc9",
  "chunked_at": "2025-12-08T14:31:53.711984",
  "total_chunks": 4,
  "chunks": [
    {
      "chunk_id": "19aadaf0f535cdc9_email_0_32248b57",
      "text": "PFA samples Ace the Data Science Interview x NYU CDS 2025.zip",
      "metadata": {
        "chunk_index": 0,
        "source_type": "email_body",
        "message_id": "19aadaf0f535cdc9",
        "from": "Abhinav Batra <ab12615@nyu.edu>",
        "to": [],
        "subject": "Test email wih different attachments",
        "date": "Sat, 22 Nov 2025 17:28:07 -0500",
        "timestamp": 1763850487,
        "token_count": 15
      }
    },
    {
      "chunk_id": "19aadaf0f535cdc9_att_Lecture-1-nyu_pdf_0_e3d1d90b",
      "text": "[CSCI-GA 3033-091] Fall 2025 Introduction to LLM based Generative AI Systems\nLecture 1   09/03/24\n1\nParijat Dube <pd2637@columbia.edu>\nChen Wang <cw3687@columbia.edu>\nClass Introduction\n‚Ä¢\nInstructors\nParijat Dube <pd2637@columbia.edu>\nAdjunct Professor, CS Dept\nMachine learning, deep learning, System performance optimization Generative AI for enterprise automation\nChen Wang <cw3687@columbia.edu>\nAdjunct Professor, CS Dept\nKubernetes, Container Cloud Platform, Data-driven/QoE based resource management, AI4Sys & Sys4AI, LLM Serving & Finetuning Sustainable Cloud & AI systems\n2\nClass Introduction\nCourse Assistants:\nAneesh Mokashi\nakm9999@nyu.edu\nGeetha Guruji gg3039@nyu.edu\nPrerequisites:\nKnowledge of ML and use of ML algorithms\nProgramming  in Python\nClass on Brightspace:\nhttps://brightspace.nyu.edu/d2l/home/504821\nAll information about the class will be available here including syllabus, announcements and assignments\n3\nToday's Agenda\nCourse Overview\nSyllabus\nAssignments and Grading\nLogistics\nMachine Learning Systems\nMachine Learning on Cloud and Model Lifecycle\nModel Performance and Complexity Tradeoffs\nClass 1 Topics\n4\nCourse Information\n¬∑ What this course will cover ?\nDL concepts, training architectures, hyperparameters\nLLM pre-training, fine-tuning and inference serving systems\nCloud based DL/LLM systems and performance issues\nLLM systems performance evaluation tools, techniques, benchmarks\nLLM systems performance optimization\nProgramming assignments involving GPUs on cloud\nResearch paper readings\n¬∑ What this course will not cover ?\nOther DL architectures like CNN, GANs, Autoencoders etc.\nMathematical analysis of DL algorithms\n5\nEducational Objectives\nIdentify different components of DL /LLM system stack and their interdependencies\nKnowledge of  ML/LLM model lifecycle and steps in making a trained model production ready\nTrain a DL/LLM model and make it a web service for inferencing\nPerformance considerations, tools, techniques at different stages of model lifecycle: development, testing, deployment.\nDL/LLM training pitfalls and techniques/best practices data processing\nAbility to train DL/LLM models on cloud platforms using GPUs\nPerformance characterization of DL/LLM systems\nKnowledge of DL/LLM benchmarks and performance metrics\nPerformance optimization of DL/LLM systems\n6\nClass 1: Fundamentals of Deep Learning (DL)\nML performance concepts/techniques: overfitting, generalization, bias, variance tradeoff, regularization\nPerformance metrics: algorithmic and system Level\nDL training hyperparameters\nbatch size, learning rate, momentum, weight decay\nSingle node vs distributed training\nModel and Data Parallelism\nParameter server, all reduce\nConvergence and runtime\nHardware Acceleration: GPUs, TPUs, NCCL\n7\nClass 2: Attention, Transformer, and Popular Large Language Models (LLMs)\nSeq2Seq models\nEncoder and decoder\nAttention mechanism\nTransformer architecture: self-attention, multi-head attention, encoderdecoder attention\nLLMs: BERT, OpenAI GPT, LLAMA, Gemini, Claude, IBM Granite\n8\nClass 3: Cloud Technologies and ML Platforms\nML System Stack on Cloud\nThis class introduces the ML system stack on cloud platforms, focusing on:\nMicroservices architecture as foundation Major cloud ML platforms Distributed training frameworks GenAI application development tools\nMicroservices Architecture\nDocker\nContainerization for consistent environments\nkubernetes\nKubernetes\nContainer orchestration for scalable deployment\nCloud ML Platforms\nAWS SageMaker\nIBM Watsonx\nDistributed Training & ML Pipelines\nago RAY\nRay\nFramework for distributed computing\n(Optional) TorchX for PyTorch-based distributed training Scalable ML workflows across clusters Efficient resource management\nGenAI Application Tools\nDify\nLLMOps platform for AI applications\nGradio\nRapid UI creation for ML models\n& gradio\nEnable rapid, often no-code prototyping of GenAI demos\nBuilding Full-Stack GenAI Systems\nPractical insights into end-to-end ML systems Integration of microservices, cloud platforms, and GenAI tools Focus on Google Cloud Vertex AI for course projects Hands-on experience with scalable deployment\nAzure ML Studio\nGoogle Vertex AI\n(Focus for course projects)\nClass 4: Prompt Engineering and LLM Apps\n‚Ä¢ Zero-shot Prompting\n‚Ä¢ Few-shot Prompting\n‚Ä¢ Chain-of-Thought,\nAutomatic CoT\n‚Ä¢\n... ...\n‚Ä¢ LangChain\n‚Ä¢ LlamaIndex\n‚Ä¢ Basics of\nPrompting\n‚Ä¢ Prompt Elements\n‚Ä¢ General Tips\n‚Ä¢ Examples\n‚Ä¢ Translation\n‚Ä¢ Code Generation\n‚Ä¢ Summarization\n‚Ä¢ Proofread and Correct\n‚Ä¢ Math Calculation\n‚Ä¢ Entity Extraction\n‚Ä¢ Call Functions\nLLM Use\nCases\nPrompt\nEngineering\nPrompt\nEngineering\nTechniques\nLLM App\nDevelopment\n10\nClass 5: RAG and LLM Agents\nCapabilities & Limitations of LLM\nKnowledge Cutoffs\nHallucinations\nStructured Data Challenge\nBiases\nRetrieval Augmented Generation\nUse Cases\nSemantic Search\nSummarization\nKeyword Search and Embeddings\nRetrieval and Rerank\nAnswer Generation\nVector Databases\n11\nClass 6: Pre-Training for LLM\nPre-training Concepts\n1.Training from existing foundation models\n2.Training from scratch\n3.Model selection from HuggingFace and PyTorch hubs\nTraining Process for Different Architectures\n1.Encoder-only models\n2.Decoder-only models\n3.Sequence-tosequence (seqto-seq) models\nManaging High Memory Requirements\n1.Quantization techniques\n2.Challenges with consumer-grade hardware\nScaling Model Training\n1.Distributed Data Parallel (DDP)\n2.Fully Sharded Data Parallel (FSDP)\n3.Zero Redundancy Optimizer (ZeRO)\nOptimizing Training Resources\n1.Balancing model size, training data volume, and compute budget\n2.Insights from the Chinchilla study\nUse Cases for Custom LLM Pretraining\n1.Domain adaptation (e.g., law, medicine)\n2.Introduction to BloombergGPT as an example\n12\nClass 7: Fine Tuning Techniques\nInstruction Fine-\nTuning, Prompt\nTuning and\nPEFT\nInstruction Fine-Tuning Process\n‚Ä¢\nTraining Data Preparation\n‚Ä¢\nDataset Splitting\n‚Ä¢\nPrompt-Completion Pairs\n‚Ä¢\nPerformance Evaluation\nMulti-task Fine-\nTuning\n‚Ä¢\nBenefits\n‚Ä¢ FLAN Models\nPEFT\n‚Ä¢\nIntroduction of PEFT\n‚Ä¢\nBenefits\n‚Ä¢ PEFT Methods\nLoRA\n‚Ä¢\nIntroduction of LoRA\n‚Ä¢\nBenefits\n‚Ä¢ Performance\nPrompt Tuning\n‚Ä¢\nExplanation\n‚Ä¢\nBenefits\nComparison and Practical\nApplication\n‚Ä¢ LoRA vs Prompt Tuning\n‚Ä¢ QLoRA\n‚Ä¢\nBenefits\n13\nClass 8: Efficient Serving of LLMs\n14\nLLM Serving\nResource\nOptimization\nBatching\n:\nStatic Batching\nDynamic Batching\nContinuous\nBatching\nMemory\nOptimization\nFlash Attention\nPaged Attention\nKernel\nUnified Paging\nLLM Serving\nFrameworks\nvLLM\nDeepspeed-MII\nTensorRT\nHuggingFace TGI\nServer\nFine-Tuned Model\nServing\nvLLM\nS-LoRA\nLoRAX\nPerformance &\nTrade-offs\nPerformance vs.\nThroughput\nFairness in\nScheduling/Routing\nGPU Techniques\nGPU Sharing\nGPU Optimization\nMultiplexing\nClass 9: RLHF\n15\nTool Learning Framework\nInstruction\nResponse\nClass 10: Tool-assisted LLMs and Agentic AI\nTool Set\nLLM\nHistory\nFeedback\nExecution\nPlanning\n16\nScheduled daily\nTool to get current location of user\nTool to send API request forecast for the day of a\nand get the weather locauoni\nLLM\nTool to send email\nEmail sent if unideal\nweather\nEmail content is tips for unideal weather conditions\nClass 10: Agentic systems\nWeather-Advisory Agent Architecture\n(1d) ReAct (Reason + Act)\nThought 1: I need to search Apple Remote and find the program it was originally designed to interact with.\nAct 1: Search[Apple Remote]\nObs 1: The Apple Remote is a remote control introduced in ront Row media cente cy designed to control the\nThought 2: Apple Remote was originally designed to control the Front Row media center program. I need to search\nFront\nRow next and find what other device can control it.\nAct 2: Search[Front Row]\nObs 2: Could not find [Front Row]. Similar: ['Front Row\nSeat to Earth', 'Front Row Motorsports',' Front Row\n(software) ', ...]\nThought 3: Front Row is not found. I need to search Front\nRow (software) .\nAct 3: Search[Front Row (software) j\nObs 3: Front Row is a discontinued media center software ...\nThought 4: Front Row (software) is controlled by an Apple\nRemote or the keyboard function keys. So the answer is keyboard function keys. Act 4: Finish [keyboard function keys ]\n17\nCommunication\nChannels\nMessoge\n4-MCP Protocol-\nMCP Host\n(Claude, IDEs, Tools)\nYour Computer\nMultiagent system Architecture\nLocall\nMCP Protocol\nWet Server Al\nResource Al\nCollaboration Stratergy\nTask\nInformation\nAllocation\nMCP Server B\nI Agent\nAgent 1\nAgent 3\nAgent 2 4\nMCP Protocol\nMCP Server C|\nQuery\nEnvironment\nPhysical\nEnvironment\nClass 11: Multi-agent System & MCP\nKnowledge Base\nSharding\nLocal\nKnowiedge\nSharing\nResource B\nKnowiedge\nSharing\nInternet\nRemote\nResource C\nMulti-agent Systems\nA pool of specialized agents collaborating to solve complex tasks\nBenefits: modularity, specialization, and control in agentic AI systems\nWe'll study connection patterns between agents\nFrameworks: LangGraph and CrewAI\nMulti-Context Protocol (MCP)\nFramework enabling LLMs to efficiently manage multiple conversations\nImproves performance and reduces computational costs\nWe'll explore MCP clients and servers development\nPractical implementations for optimizing LLM interactions\nAdvanced AI Frameworks for Collaborative Intelligence\n-Web APIs.\n–≠6\nClass 12: Multimodal Generative AI systems\nDefinition & Importance\nDefinition : Process multiple data types (text, images, audio, video).\nImportance : Human-like perception and interaction.\nBeyond Language Models\nExpansion : Incorporate visual, auditory, sensory inputs.\nExamples : DALLE, GPT-4 with vision.\nCreating Large Multimodal Models (LMMs)\nIncorporation : Additional modalities into LLMs.\nArchitectures : Encoder-decoder, transformer-based.\nTraining : Crossmodal, contrastive learning.\nFlamingo : Visual language model, few-shot learning.\nThe Multimodality Revolution\nShift : From unimodal to multimodal AI.\nAdvancements : Computer vision, speech recognition, NLP.\nIntegration : Unified models.\n19\nClass 12: Emerging Topics: Multimodal Generative AI\nVision-Language Models & Voice LLM | 21-11-2025\nMultimodal AI & LMMs\nHands-on Project\nClass 12: Emerging Topics: Multimodal Generative AI\n‚Ä¢ VLMs: Vision-Language Models for visual reasoning\nVision-Language Models & Voice LLM | 21-11-2025\nMultimodal AI & LMMs\nBeyond LLMs:\nProcessing multiple data types simultaneously\nLMMs:\nSpecialized encoders with shared reasoning layers\nVLMs: Vision-Language Models for visual reasoning\nApplications:\nHealthcare, retail, robotics, education\nAl Voice Agents\nDefinition: Systems for real-time conversations\n*o Architecture: STT ‚Üí NLU ‚Üí LLM ‚Üí TTS pipeline\n% Latency: Critical for natural conversation flow\nAI Voice Agents\n\"The future of Al is multimodal, integrating multiple senses like human intelligence.\"\nDefinition: Systems for real-time conversations\nArchitecture:\nSTT ‚Üí NLU ‚Üí LLM ‚Üí TTS pipeline\nLatency: Critical for natural conversation flow\nHands-on Project\nGoal: Build production-ready voice agent\nPartners:\nLiveKit, RealAvatar, ElevenLabs\nLearning:\nPipeline, optimization, deployment\nFuture Directions\nPretraining\nStage2:Multi-task\nUnified Models:\nSingle architectures for all modalities\nEmbodied AI:\nIntegration with physical interaction\nLearnable\nQuery\nEmbs\nLeamnable\nOvaryl\nEmbs\n\"The future of AI is multimodal, integrating multiple senses like human intelligence.\"\nViT\nImage-Text Pairs\nVIT\nMulti-task and\nInterleaved VL Data\nViT\nChat Interleaved\nVL. Data\nThe rating age line the One a nong: (cle Bo, Tet he go an end Ma. 8: 2306. 7294, (\nC 8 Thou 1 12022) Owen.V ‚Ä¢ A Vercatilel\nCrossAttr\nQuery\nStage3: Supervised\nFinetuning\nQwenLM\nClass 13: LLM Benchmarks\nLLM Benchmarks\n21\nPurpose &\nMotivation\n:\nPurpose\nEvaluate\nperformance,\nEfficiency &\nLimitations.\nMotivations\nAccuracy,\nspeed,\nreliability.\nTypes of\nBenchmarking\nModel\nPerformance,\naccuracy\nmetrics.\nSystem\nEfficiency\nScalability\nResources\n.\nEvaluation\nMetrics\nROUGE\nBLEU\nN-grams\nPrecision/Re\ncall/F1\nAdvanced\nTechniques\nComprehensive\nBenchmarks\n:\nGLUE\nSuperGLUE\nMMLU\nBIG-\nbench\nHELM\nUnseen Data\nEvaluation\nGeneraliz\nation\nRisks\nTools\nMLPerf\nLLMPerf\nHuggingFace\nLeaderboard\nFmperf\nRecommended Books\nThis course does not follow any  textbook\nBackground knowledge\nList of books (covering deep learning topics)\nCharu Aggarwal 'Neural Networks and Deep Learning',  available at https://link.springer.com/book/10.1007/978-3-319-94463-0\nGoodfellow, Bengio, Courville, 'Deep Learning', available at http://www.deeplearningbook.org\nThese books are good for basic DL understanding\nFor basics of machine learning concepts an excellent textbook is G. James et al ' Introduction to Statistical Learning Theory '. Second version available is available for free download at https://www.statlearning.com\nAll other reading material will be posted on Canvas.\n22\nAssignments and Grading\n¬∑ Distribution of marks :\nAssignments: 40%\nQuizzes: 20%\nFinal Project: 40%\n¬∑ Assignments (40%)\n5 assignments\nAssignments posted at the end of lectures 2, 4, 6, 8, 10; due in 2 weeks\nAll programming assignments should be done as Jupyter notebooks, unless specified otherwise\n¬∑ Quizzes (20%)\nCanvas\n5 quizzes\n23\nAssignments and Grading (contd.)\nFinal Project (40%): Team assignment. Team of 2. Any project involving development of new LLM solutions and/or performance optimization of existing LLM systems. 2-page project proposal due by Midterm. Detailed rubric shall be provided. Project grading:\nProject proposal (5%) - due in mid October\nMidpoint checkpoint (5%)  - due before Thanksgiving break\nGithub repo with README, documented code (5%)\nFinal presentation and demo (15%)\n24\nClass Logistics\nReach CAs: Office hours and Campuswire\nAccess to Computer Clusters\nClass communications:Campuswire\n25\n/A.I. TIMELINE\n1950\n1955\nTURING TEST\nComputer scientist\nAlan Turing proposes a\nA.I. BORN\nTerm 'artificial\n1961\nUNIMATE\nFirst industrial robot,\n1964\nELIZA\nPioneering chatbot intelligence' is coined\nUnimate, goes to work intelligence\ndeveloped by Joseph\nAI  Timeline\n1999\nAIBO\nSony launches first consumer robot pet dog autonomous robotic\nAiBO (Al robot) with skills and personality\nthat develop over time\nInflection point in AI adoption is tied to innovations in computing and availability of big data Jeopardy comments number (2170) of\nCloud computing was coined\nO: AlphaGo\n2002\n2011\nROOMBA\nSIRI\nFirst mass produced\nApple integrates Siri,\nan intelligent virtual\nvacuum cleaner from assistant with a voice iRobot learns to navigate interface, into the and clean homes iPhone 4S\n2011\nWATSON\nIBM's question\nanswering computer\nWatson wins first place on popular $1M prize television quiz show Turing Test with a third of judges believing Eugene is human\n2014\nEUGENE\nEugene Goostman, a\nchatbot passes the\n2014\nALEXA\nAmazon launches Alexa.\nan intelligent virtual\nassistant with a voice interface that completes shopping tasks media making inflammatory and offensive racist\n2016\nTAY\nMicrosoft's chatbot Tay\ngoes rogue on social\n2017\nALPHAGO\nGoogle's A.l. AlphaGo\nbeats world champion\nKe Jie in the complex\nboard game of Go, notable for its vast\n2006: Amazon elastic cloud and S3 was launched\n1966\nSHAKEY\nThe 'first electronic person' from Stanford,\nA.I.\nWINTER\nMany false starts and\n1997\nDEE.\nDeep Blue, a chess- playing computer from\n1998\nKISMET\nCynthia Breazeal at MIT\nintroduces KISmet, an\nSIZIGY\n26\nFactors Contributing to AI Success\n¬∑ Algorithms, Data, Compute, Applications\nDistributed training algorithms scaling upto 100s of GPUs\nData growing at exponential rate; Internet, Social media, Internet of thngs (IoT)\nCompute power growth with specialized cores; GPUs, TPUs\nDevelopment of innovative applications\n2012 Alexnet by Krizhevsky et al at ImageNet Competition\nSimple convolutional neural network: 5 convolutional, 3 fully connected\nGPU based; Beat other models by 11% margin\nTriggered 'Cambrian Explosion' in deep learning technologies\n' Neural networks are growing and evolving at an extraordinary rate, at a lightening rate,‚Ä¶.What started out just five years ago with AlexNet‚Ä¶five years later, thousands of species of AI have emerged .'\n27\nTransformers\nArchitecture\nAug 2017\nGPT-2\n1.5B Param\nFeb 2019\nMed-PaLM2\nMEENA\n2.6B Param\nJan 2020\nLLaMA\nBERT\n480B Param\nNov 2021\n‚Ä¢\nAtlas\nGopher\n280B Param\nDec 2021\n–°–ú3\nEvolution of Large Language Models (LLMs)\nJourney\nContinues\nBloombergGPT\nMed-PaLM\nZ-Code++\nPaLM\n340B Param\n50B Param\nApr 2023\nMar 2023\nDec 2022\n710M Param\nAug 2022\nApr 2022\nGPT-4\n540B Param\nFigure from Mohamadi et al, ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey\n‚Ä¢\nLaMDA\n137B Parm\nJun 2021\n‚Ä¢\n28\nAI Blogs of Major Companies\nMeta: https://ai.meta.com/blog/\nGoogle: https://ai.googleblog.com\nIBM Research:\nhttps://www.ibm.com/blogs/research/category/ai/\nMicrosoft: https://news.microsoft.com/source/topics/ai/\nAWS Machine Learning Blog: https://aws.amazon.com/blogs/machine-learning/\n29\nMachine Learning System\nA composition of one or more software components, with possible interactions, deployed on a hardware platform with the purpose of achieving some performance objective.\nA Machine Learning system is a system where  one or more software components are machine learning based .\nWhy study ML systems ?\nAlgorithms run on real and (possibly) faulty hardware in production environments\nTheoretical performance is far away from observed\nTo characterize holistic performance of not just the algorithm but the end-to-end performance of the entire system\n30\nConstituents of a ML System\nMachine Learning\nSystem\nData\nAlgorithm(s)\nSoftware Platform\nHardware/\nInfrastructure\nModel\n31\nInfrastructure\nCompute units and accelerators, memory, storage, network\nResources can be acquired as bare metal, VMs/Containers on cloud\nDesign better hardware\nAdapt existing architectures to ML tasks.\nDevelop brand-new architectures for ML.\nHardware compute precision affects performance: tradeoff between accuracy and runtime\n32\n(Learning) Algorithm\nGeneral and domain specific architectures\nHyperparameter tuning to extract the best performance\nEffects the resource requirements: compute (FLOPS), memory\nPerformance (runtime) and scalability of an algorithm depends on:\nHardware/Infrastructure\nSoftware platform (frameworks, libraries, drivers)\n33\nData\nData as a critical element; Data is the king in ML\nDifferent modalities: Audio, video, images, text\nData sources, collection, labeling, quality, data storage\nData type determines the choice of learning algorithm\nMaking the data business ready is challenging\nMany data-driven organizations are spending 80 percent of their time on data preparation and find it a major bottleneck.\nDataOps: tools, processes, and organizational structures to cope with significant increase in volume, velocity, and variety of data.\n34\nEnd-to-end traceability\nPLAN\nCONTINOUS\nINTEGRATION\nCODE\nFEEDBACK\nCONTINUOUS\nSoftware Engineering in ML Systems\nMachine learning applications run as pipelines that ingest data, compute features,  identify model(s), discover hyperparameters, train model(s), validate and deploy model(s).\nMaking a model as a production-capable web service\nContainerization (docker), cluster deployment (K8s)\nAPIs exposed as web service (Tensorflow serving/ONNX runtime)\nWorkflow engines (e.g., Kubeflow) automate the ML pipeline\nDeployment monitoring and operational analytics\nDevops principles applicable to ML Systems:\nContinuous Integration, Continuous delivery (CI/CD)\nPredictability\n'A model may be unexplainable-but an API cannot be unpredictable'\nReproducibility and Traceability\nProvenance for machine learning artifacts\nML specific testing and monitoring apart from traditional software testing\nData testing\nInfrastructure testing\nModel testing\nProduction testing\nDEPLOY\n35\nInhibitors in Successful Implementation of ML Solutions\nDeployment and automation\nReproducibility of models and predictions\nDiagnostics\nGovernance and regulatory compliance\nScalability\nCollaboration\nMonitoring and management\n36\nCloud Computing\nAccess to computing resources and storage on demand\nPay-as-you go model\nHeterogeneous resources: GPUs, CPUs, storage type\nDifferent offering models: IaaS, PaaS, SaaS, MLaaS\nDifferent deployment models: Public, private, hybrid cloud\nProvisioning, maintenance, monitoring, life-cycle-management\n37\nCLOUD\nCloud and AI\nComputer\nAI\nHarness power of Big Data and compute\nTablet computer\nWearable device\nCloud\nUnmanned truck\nAccess to Big Data\nPlatform to quickly develop, deploy, and test AI solutions\nEase in AI reachability\nIOT\nAL\nHouse\nRobot\nPet\nYuichi Yoda\n38\nCloud based Machine Learning Services\nIBM Watson Studio\nhttps://www.ibm.com/products/watson-studio\nAmazon Sagemaker\nhttps://aws.amazon.com/sagemaker\n‚Ä¢\nMicrosoft Azure Machine Learning\nhttps://azure.com/ml\n‚Ä¢\nGoogle Vertex AI Platform\nhttps://cloud.google.com/vertex-ai/\n39\nLayer 8: Observability & Management Layer miflow\nOpenTelemetry\nMLflow\nOpenLLMetry\nMonitoring\nLayer 7: Orchestration & Application Layer\nGenAI on Cloud Stack\nKServe\nVLLM\nNVIDIA Triton\nEnvoy AI\nLayer 5: Fine-Tuning & Development Layer\nAxoloti\nLayer 4: Data & Model Management Layer\nModel Catalog\nLayer 3: Cloud-Native Storage Layer\nPortworx\nLayer 2: Orchestration Layer\nKubernetes\nLayer 1: Cloud Hardware & Accelerated Compute\nHigh-Performance CPUs\nUnsloth\nTorchtune\nHugging Face\nTools and frameworks for customizing pre-trained models\nPEFT\nCentralized management of models, data, and metadata\nVector DBs\nPostgreSQL\nMongoDB\nData Lakes\nPersistent, scalable storage for models, data, and artifacts\nRWX Volumes\nPersistent Volumes\nManages and orchestrates hardware resources for GenAl workloads\nSlurm\nGPU Operator\nContainer Toolkit\nProvides the raw computational power required for GenAl workloads\nSpecialized GPUs\nHigh-Speed Storage\nHigh-Bandwidth Networking\nGenAI on Cloud Full Stack\nMonitoring, management, and governance across the entire stack\nBuilding complex GenAI applications and workflows\nHigh-performance model serving and inference optimization\n40\nAccuracy\nMonitoring\nModel\nServing\nModel\nHardening\nParameter\nTuning\nAI Model Training Lifecycle\nData\nFeature\nPreprocessing\nEngineering\nModel Training\nLifecycle\nPerformance considerations at each stage\nData preprocessing: de-noising, de-biasing, train/test set creation\nFeature engineering: search efficient data transformations\nModel training: model identification/synthesis, hyperparameter tuning, regularization\nModel hardening: efficient adversarial training\nModel serving:  hardware, model pruning and compression\nMonitoring: response time, drift detection\nContinuous learning: model adaptability, retraining\n41\nConfiguration\nData Collection\nServing\nPractical Machine Learning Systems\nFeature\n‚úî\n‚úî\n‚úî\n‚úî\n‚úî\n‚úî\n‚úî\nExtraction\nManagement Tools\nProcess\nData\nVerification\nMachine\nResource\nManagement\nMonitoring\n42\nClass 1: Fundamentals of Deep Learning (DL)\n43\nTSS = [(yi -y)?\nTSS - RSS\nTSS\nf=B +Bx1 + B2x2+...\nR? =\nRSS =\nMiles per gallon\n06 006\nLinear Regression\n+ –í—Ä—Ö—Ä.\nResidual Plot for Linear Fit\n3230\n0334\n3300\n308\n100\n150\nHorsepower\n200\nRSS\nTSS\nDegree 2\nDegree 5\n50\ni=1\n= 1 -\n5\n10\n8\n155¬∞\n15\n20\nFitted values\n25\n15\n20\n30 35\n25\nFitted values\n8\n9899\nResidual Plot for Quadratic Fit\n0334\n3230\n44\n√ù = f(X)\nMSE ==\nn\n20\n40\n60\n80\nChOL 1\n2.0\n- IlVi - f(xi)) 3\ni=1\n100\n2\n5\n10\n20\n20\n40\n60\n80\n100\n2\nMean Square Error (MSE)\n1\nn\nCASE 1\nCASE 2\nCASE 3\ntrue value\npredicted\n‚Ç¨(n.112\nMean Squared Error\n1.5\n1.0\nCASE 2\n2.0\nMean Squared Error\n10\nFlexibility\n20\n20\n40\n60\n80\nLASE S\nMean Squared Error\n100\n5\n10\nFlexibility\n20\n45\nOverfiYng and UnderfiYng\n20\n80\n100\nOverfi]ng: model performs well on training data but does not generalize well to unseen data (test data)\nUnderfi]ng: model is not complex enough to capture pa^ern in the training data well and therefore suffers from low performance on unseen data\n46\nThe Bias-Variance Trade-Off\nOPTIMAL\nCOMPLEXITY\nOVERALL ERROR\nSQUARED ERROR\n‚Ä¢ Optimal point of model complexity is somewhere in middle.\nVARIANCE,\nMODEL COMPLEXITY\n47\n2.5\n2.0\n1.5\n2\nE (y0 - f(xo))\n2.5\n2.0\n1.5\nModel Complexity Tradeofffs\nCASE 1\nCASE 2\nCASE 3\n5\nT\n10\nFlexibility\n20\n2\n5\nT\n10\nFlexibility\n20\n2\n5\n10\nFlexibility\n20\n= Var (f (xo)) + [Bias(f (xo))]¬™ + Var(c)\nCHOL 1\nChOL <\n15\nMSE\nBias\nVar\n48\nPrediction Error\nHigh Bias\nLow Variance\nSimple model\nFail to completely capture the relaZonship between features\nIntroduces bias: Consistent test error across different choices of training data\nLow variance\nIncreasing training data does not help in reducing bias\nComplex model captures nuances in training data causing Overfieng\nLow bias\nTrain error << Test error\nWith different training instances, the model predicZon for same test instance will be very different - High Variance\nLow Bias\nHigh Variance\n.....--/\nModel Complexity Tradeoffs\nGap\nGeneraliza>on\nGap\n49\nLow Bias\nHigh Bias\nLow Variance\nHigh Variance\nBias-Variance Tradeoff\nHigh Bias\nLow Bias\nIncrease model complexity\nHigh Variance\nIncrease training data\nLow Variance\n50\nRegularizaEon\nTechniques used to improve generalizaSon of a model by reducing its complexity\nTechniques to make a model perform well on test data oTen at expense of its performance on training data\nAvoid overfiVng, reduce variance\nSimpler models are preferable: low memory, increase interpretability\nHowever simpler models may reduce the expressive power of models\nSample techniques:\nParameter norm penalKes\nùë≥ ùüê and ùë≥ ùüè norm weight decay\nNoise injecKon\nDropout\n51\n(LASSO)\n400\nn\nn\nStandardized Coefficients\nStandardized Coefficients\n300\n‚Ä¢ ' –£—ñ-–í–æ-!\n200\ni=1\ni=1\n100\n-100\n-300\n1e-02\n400\n300\n200\n100\n-200\n20\n50\n100\n200\n500\n2\n2\n+1 21811\n400\nj=1\n100 200 300\nj=1\n-100\nStandardized Coefficients\nRegulariza_on in Regression\nùë≥ ùüê Regularization Loss (Ridge Regression) 300 400 ... ...... ¬∑\nLimit\nRating\nStudent\n2000\n5000\nùë≥\n0.0\n0.2\nWhat value of lambda to choose ?\n1.0\nIncome\nLimit\nRating\nStudent\nBixig )\n(1-80-284))\n0.4\n0.6\n0.8\n52\n52\nMean Squared Error\n60\n50\n40\n30\n20\n10\n60\n50\n40\n30\n20\nBias-variance tradeoff with Lambda\n10-01\n1e+03\n0.0\n0.2\n0.4\n0.6\n|BR 12/1181|2\n0.8\n1.0\n53\nPerformance Metrics\nAlgorithmic performance: accuracy, precision, recall, F1-score, ROC,\nSystem performance: training ame, inference ame, training cost, memory requirement, training efficiency\n54\nPredicted value\nAccuracy =\ntp + tn tp+tn+ fp+fn\nPrecision =\ntp tp + fp\nFalse discovery rate = 1-Precision\nRecall =\ntp + fn\nTrue negative rate =\ntn tn + fP\nAccuracy, Precision, Recall, Specificity\nfalse negative (fn)\nPositive\nNegative\nNegative\nPositive\ntrue positive (tp)\ntrue negative (tn)\nfalse positive (fp)\nTrue value\nBalanced accuracy =\n(ùëÜùëíùëõùë†ùëñùë°ùëñùë£ùëñùë°ùë¶ + ùëÜùëùùëíùëêùëñùëìùëñùëêùëñùë°ùë¶)/2\nConsiders all entries in the confusion matrix Value lies between 0 (worst classifier) and 1 (best classifier)\n55\nF1 =\n2\nprecision ‚Ä¢ recall recall-1 + precision -1\nFp = (1 + B¬™).\n‚Ä¢ EB\nprecision ‚Ä¢ recall precision + recall\ntp tp + ‚Öñ(fp + fn)\n= 2.\n√ü ‚Ä¢ precision + recall score: B = 1 is F1 score; recall is considered\nBalancing Precision and Recall\nF1 score: Harmonic mean of precision and recall; measure of classifier accuracy\n¬∑ ùë†ùëêùëúùëüùëí: \tùõΩ = 1\tùëñùë†\tùêπ1\tùë†ùëêùëúùëüùëí ; recall is considered Œ≤ ames as important as precision\n=\n56\n1.0-\n0.8\n0.6 g\n0.4\n0.2 1\n0.0.0\nTrue Positive Rate\nROC Curves\nReceiver Opera_ng Characteris_cs (ROC)\nPlots true posiave rate (Recall) vs false posiave rate at different thresholds\n57\n‚Ä¢ DL performance is closely tied to the hardware\n‚Ä¢ compute power, memory, network\n‚Ä¢ Tesla V100: 640 tensor cores (> 100 TFLOPS), 16 GB\n‚Ä¢ NVIDIA NVLink: 300 GB/s\nDL Training Time\nDeep Learning Training in Less Than a Workday\nDL performance is closely aed to the hardware\ncompute power, memory, network\nTesla V100: 640 tensor cores (> 100 TFLOPS), 16 GB\nNVIDIA NVLink: 300 GB/s\nVolta opimized CUDA libraries\nPASCAL\nVOLTA TENSOR CORES\n58\n58\n47X Higher Throughput Than CPU Server on Deep\nLearning Inference\nTesla V100\nTesla P100\n15X\nDL Inference Throughput\nPerformance Normalized to CPU\nWorkload: ResNet-50 | CPU: 1X Xeon E5-2690v4 @ 2.6 GHz | GPU: Add 1X Tesla P100 or V100\n47X\n59\nX.\nN\n–•–∑\nOUT PUT LAYER\n‚Üí –£\nDeep Learning Training\nForward phase\nLoss calculaion\nBackward phase\nWeight update\nForward Phase\nBackward Phase\nCompute Loss\nINPUT LAYER\nHIDDEN LAYER\nL.\n60\nDeep Learning Training Steps\n¬∑ Forward phase:\ncompute the acKvaKons of the hidden units based on the current value of weights\ncalculate output\ncalculate loss funcKon\n¬∑ Backward phase:\ncompute parKal derivaKve of loss funcKon w.r.t. all the weights;\nuse backpropaga8on algorithm to calculate the parKal derivaKves recursively\nbackpropagaKon changes the weights (and biases) in a network to decrease the loss\nUpdate the weights using gradient descent\n61\nStochas_c Gradient Descent (SGD)\nLoss is calculated using one training data at each weight update\nStochastic gradient descent is only a randomized approximation of the true loss function.\n62\nHyperparameters in Deep Learning\nNetwork architecture: number of hidden layers, number of hidden units per later\nAcavaaon funcaons\nWeight iniaalizer\nLearning rate\nBatch size\nMomentum\nOpamizer\n63\nCost\nLearning step\nRandom\nCost\nStart\nStart\n‚Ä¢ 0\nLearning rate: large value vs small value\nconverge to cost minima and the cost might keep increasing with\nfurther training loops.\ntraining loops to arrive at cost minima.\nImage Credit : \"Hands-on Machine Learning with Scikit-Learn and TensorFlow\" by Aurelien Geron\nMinimum\nCost\nBatch size\nEffect of batch size on learning\nBatch size is restricted by the GPU memory (12GB for K40, 16GB for P100 and V100) and the model size\nModel and batch of data needs to remain in GPU memory for one iteraKon\nBatch size tradeoffs\nHardware constraints (GPU memory) dictate the largest batch size\nShould we try to work with the largest possible batch size ?\nLarge batch size gives more confidence in gradient esKmaKon\nLarge batch size allows you to work with higher learning rates, faster convergence\nLarge batch size leads to poor generalizaSon\nLands on sharp minima wheareas small batch SGD find flat minima which generalize beTer\nSmall batches introduce stochasKc noise into gradient esKmates, which acts as implicit regularizaKon by helping the opKmizer escape sharp local minima\n65\nSingle Node, Single GPU Training\nTraining throughput depends on:\nNeural network model (acKvaKons, parameters, compute operaKons)\nBatch size\nCompute hardware: GPU type (e.g., Nvidia M60, K80, P100, V100)\nFloaKng point precision (FP32 vs FP16)\nUsing FP16 can reduce training Rmes and enable larger batch sizes/models without significantly impacRng the accuracy of the trained model\nIncreasing batch size increases throughput\nBatch size is restricted by GPU memory\nTraining Sme with single GPU very large: 6 days with Places dataset (2.5M images) using Alexnet on a single K40.\nSmall batch size => noisier approximaSon of the gradient => lower learning rate => slower convergence\n--QPI\n‚Ä¢ PCI-e switch\n-- PCI-e O GPU\n‚Äî NVLink ¬© CPU\nCO\nX-Bus\nGOO\nNVLink-V1\nGO\nG1,\n‚Ä¢\nG1\nSPI\nNVLink-V2\n063\n√ìG2\nG2\n(A) SummitDev\nNVLink\nG40\nG3\nG7\nCO\nX-Bus\nGO\nG1\nG1,\nNVLink\nG2\nC1\nO.\nG4\nG3\n(B) Summit\nG4 Q\nOPI\nG3\n‚Ä¢ G7\nFig. 2: NVLink interconnect topology for SummitDev and Summit.\nG5\nPci-e\nG6\nG6\nPCI-e\nMul5-GPU Execu5on Scaling\nCuolunting Madorn CDIl Intarcannant.\nVeracal scaling-up in a single node\nNVIDIA DGX-1 (8 P100 GPUs) and DGX-2 (16 V100 GPUs) servers\nHorizontal scaling-out across multiple nodes\nExample: GPU accelerated supercomputers like Summit and Sierra from US Department of Energy\nEvalua[ng Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and GPUDirect\nG5\nG2\nGO\nSingle Node, Mul_ GPU Training\nCommunication libraries (e.g., NCCL) and supported communication algorithms/collectives (broadcast, all-reduce, gather)\nNCCL ('Nickel') is library of accelerated collectives that is easily integrated and topology-aware so as to improve the scalability of multi-GPU applications\nCommunication link bandwidth: PCIe/QPI or NVlink\nCommunication algorithms depend on the communication topology (ring, hub-spoke, fully connected) between the GPUs.\nHigh Performance Networking\nLarge Scale Parallel and Deep Learning applicaaons needs:\nHigh Bandwidth\nLow Latency\nEthernet is not enough\nInfiniband (IB) is widely adopted\nCustom Networks are the best\n69\nCPU\nGPU.\nPCle: Peripheral Component Interconnect express\nSMP: symmetric multiprocessing\nQPI: Quick-path interconnect (25.6 GB/s)\nGPU3\nRing based collectives\nGPUO\nSMP Connection\n(e.g., QPI)\nPCIe: Peripheral Component Interconnect express\nSMP: symmetric multiprocessing\nQPI: Quick-path interconnect  (25.6 GB/s)\nPCIe: Peripheral Component Interconnect express\nSMP: symmetric multiprocessing\nQPI: Quick-path interconnect  (25.6 GB/s)\nCPU\nSwit sh\nCPU\nwitch\nGPUZ\nGPU3\nGPU4\n5\nGPUS\nGPU7\n1‚Ç¨\nDistributed Training\nType of Parallelism: Model, Data, Hybrid\nType of AggregaSon: Centralized, decentralized\nCentralized aggregaSon: parameter server\nDecentralized aggregaSon: P2P, all reduce\nPerformance metric: Scaling efficiency\nDefined as the raKo between the run Kme of one iteraKon on a single GPU and the run Kme of one iteraKon when distributed over n GPUs.\nParallelism\nParallel execuaon of a training job on different compute units through scale-up (single node, mulaple and faster GPUs) or scale-out (mulaple nodes distributed training)\nEnables working with large models by paraaoning model across learners\nEnables efficient training with large datasets using large 'effecave' batch sizes (batch split across learners)\nSpeeds up computaion\nModel, Data, Hybrid Parallelism\nen lanet la Blande\nLearner 2\nModel Parallelism\n¬∑ Splitting the model across multiple learners\nLearner 1\nLearner 3\nLearner 2\nLearner 4\n5 layered neural network\nPartitioned across 4 learners\nBold edges cross learn boundaries and involve inter-learner communication\nPerformance benefits depend on\nConnectivity structure\nCompute demand of operations\nHeavy compute and local connectivity -benefit most\nEach machine handles a subset of computation\nLow network traffic\nDevice 3\nDevice 2\nDevice 1\nDevice 0\nLoss\n–í–≥\n(b)\nGPipe Pipelining\nGradients\n(a)\n–í2.3\nB.\nB3.1\nB22\nB3.0\nB2.1\nB.\nB2.0\nUpdate\nUpdate\nUpdate\nUpdate\nUpdate\nUpdate\nF1,0 F1.1 F12 F1.3\nBubble\nFoo For Foz Fo,s\n(c)\nB1.3\nB1.2\nB1.1\n–í–æ–∑ Bo2\nB1,0\nBo, 1\nBo,0\nMILI\nUpdate\nUpdate\nGpipe: a pipeline parallelism open-source library that allows scaling any network that can be expressed as a sequence of layers.\nSplit global batch into multiple micro-batches and injects them into the pipeline concurrently\nNot memory-friendly and will not scale well with large batch. The activations produced by forward tasks have to be kept for all micro-batches until corresponding backward tasks start, thus leads to the memory demand to be proportional (O(M)) to the number of concurrently scheduled micro-batches (M).\nFo\nFo\n1 1\nFo\nB.\nTime\n–í.\nHPML\nGPipe: Easy Scaling with Micro-Batch Pipeline Parallelism\n74\nModel Parallelism and model saving technique in Amazon Sagemaker model parallel library\nPipeline Parallelism\nTensor Parallelism\nOptimizer state sharding\nActivation offloading and checkpointing\nhttps://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-intro.html\nPartition 0\nPartition 1\nL1\nL2\nL3\nL4\nSample model with four layers\nBatch 1\nBatch 2\nmicrobatch 1\nmicrobatch 2\nmicrobatch 3\nmicrobatch 4\nL1\nL2\nGPU 0\nL3\nGPU 1\nMP_GROUP=PP_GROUP\nmicrobatch 1\n\"microbatches\": 4,\n\"pipeline_parallel _degree\": 2,\n\"ddp\": True,\nModel parallel configuration\nBatch 3\nBatch 4\nmicrobatch 1\nmicrobatch 1\nPipeline Parallelism\nDP_GROUP\nL2\nL1\nL2\nL1\nL2\nGPU 4\nGPU 6\nL4\nL3\nL4\nL3\nL4\nGPU 5\nGPU 7\nL1\nGPU 2\nL3\nGPU 3\nML instance with eight GPU workers\nfour-way data parallelism\ntwo-way pipeline parallelism\nEach model replica is a PP_GROUP ( pipeline parallel group ) and is partitioned across two GPUs\nEach partition of the model is assigned to four GPUs, where the four partition replicas are in a data parallel group and labeled as DP_GROUP\nL1\nBatch 1\nL2\nDP_GROUP\nTensor Parallelism\nGPU O\nMP GROUP=TP_ GROUP\nL1\nL2\nGPU 1\nBatch 2\nGPU 2\nGPU 4\n\"tensor_parallel_\n_degree\": 2,\n\"pipeline_parallel_degree\": 1,\n\"ddp\": True\nModel parallel configuration\nBatch 5\nBatch 7\nL1\n....\nL2\nL3\nL4\nGPU 6\nL3\nL4\nL1\nL2\nL3\nGPU 3\nL4\nBatch 4\nL1\nL2\nL3\nGPU 5\nL4\nL1\nL2\nL3\nGPU 7\nBatch 6\nBatch 8\nL1\nL2\nL3\n-\nSample model with four layers\nBatch 3\nSplits individual layers, or nn.Modules , across devices, to be run in parallel\ntwo-way tensor parallelism\ndegree of data parallelism is eight\nL1\nL1\nOptimizer\nState for L1\nL2\nGPU O\nL2\nL3\nGPU 2\nOptimizer\nState for L3\nL1\nL2\nL3\nSample model with four layers\nOptimizer for L2\ndon't need to replicat a single replica of the\nno redundancy acros:\nTimeline on GPU 0\nduring a backward propagation\nOp5mizer state sharding\nNetwork\nR\nReduce collective\nL2\nL3\nGPU 3\nOptimizer\nState for L4\nL4\nL1\nL4\nAG\ndon't need to replicate your optimizer state in all of your GPUs a single replica of the optimizer state is sharded across data-parallel ranks, with no redundancy across devices\nState\nAll-gather collective\nModel\nReplicas\nData\nShards\nData Parallelism\nLearner 1\nLearner 2\nLearner 3\nModel is replicated on different learners\nData is sharded and each learner work on a different pariion\nHelps in efficient training with large amount of data\nParameters (weights, biases, gradients) from different replicas need to be synchronized\nModel\nReplicas\nData\nParameter server (PS) based Synchroniza_on Shards\n‚àÜùë§\n!,#\n‚àÜùë§\n!,$\nùë§\n!%$\nùë§\n!%$\nParameter Server\nEach learner executes the enSre model\nATer each mini-batch processing a learner calculates the gradient and sends it to the parameter server\nThe parameter server calculates new value of weights and sends them to the model replicas\nSynchronous SGD and the Straggler problem\nPS needs to wait for updated gradients from all the learners before calculaang the model parameters\nEven though size of mini-batch processed by each learner is same, updates from different learners may be available at different ames at the PS\nRandomness in compute ime at learners\nRandomness in communicaion ime between learners and PS\nWaiang for slow and straggling learners diminishes the speed-up offered by parallelizing the training\nPS\nFully Sync-SGD\nWo\nWI\nK-sync SGD\nWo WI\nPS\nK-batch-sync SGD\nps e\nW1.\nW2\nSynchronous SGD Variants\nP: total number of learners\nK: number of learners/minibatches the PS waits for before updating parameters\nLightly shaded arrows indicate straggling gradient computations that are canceled.\nK-sync SGD: PS waits for gradients from K learners before updating parameters; the remaining learners are canceled\nWhen K = P , K-sync SGD is same as Fully Sync-SGD\nK-batch sync: PS waits for gradients from K mini-batches before updating parameters; the remaining (unfinished) learners are canceled\nIrrespective of which learner the gradients come from\nWherever any learner finishes, it pushes its gradient to the PS, fetches current parameter at PS and starts computing gradient on the next mini-batch based on the same local value of the parameters\nRuntime per iteration reduces with K-batch sync; error convergence is same as K-sync\nAsynchronous SGD and Stale Gradients\nPS updates happen without waiang for all learners\nWeights that a learner uses to evaluate gradients may be old values of the parameters at PS\nParameter server asynchronously updates weights\nBy the ime learner gets back to the PS to submit gradient, the weights may have already been updated at the PS (by other learners)\nGradients returned by this learner are stale (i.e., were evaluated at an older version of the model)\nStale gradients can make SGD unstable, slowdown convergence, cause sub-opamal convergence (compared to Sync-SGD)\nWorker 1\nWorker 2\nParam. Version\nWor\nWos\n100\n101\n102\nWiol\nW102\n103\n104\n105\n106\nW/01= W/00 - 24W,7\nWoz= Wor - 24W,s\nStale Gradient Problem in Async-SGD\nWorker 3\nWorker 4\nW100\nW99\nW103\nW104\nblog.skymind.ai Distrbuted Deep Learning, Part 1: An IntroducJon to Distributed Training of Neural Networks\nTime\nblog.skymind.ai Distrbuted Deep Learning, Part 1:\nIntroduction to Distributed Training of Neural Netw\nPS\nAsync SGD\nWo W,W,W3\nK-async SGD\nWo\nPS\nW1\nW3\nK-batch-async SGD\nWo\nW1\n2\nW3\nW\nPS\nAsynchronous SGD and Variants\nK-asvne SGD: PS waits for cradients from K learners before undating narameters but the remaining learners are not canceled: e\nK-async SGD: PS waits for gradients from K learners before upda>ng parameters but the remaining learners are not canceled; each learner may be giving a gradient calculated at stale version of the parameters\nWhen K = 1 , K-async SGD is same as Async-SGD\nK-batch async: PS waits for gradients from K mini-batches before updating parameters; the remaining learners are not canceled\nWherever any learner finishes, it pushes its gradient to the PS, fetches current parameter at PS and starts computing gradient on the next mini-batch based on the current value of the PS\nRun>me per itera>on reduces with K-batch async; error convergence is same as K-async\n7.5\n5.0\n‚Ä¢ 2.5\n0 -2.5\n-7.5\nsame learnina rate\n- - -\nK-Batch Async\nK-Async SGD\nConvergence-Runtime Tradeoff in SGD Variants K=3 K=4\n2\n3\n4\n5x 105\n‚Ä¢ Error-runtime trade-off for Sync and Async-SGD with\nError-runtime trade-off for Sync and Async-SGD with same learning rate.\nAsync-SGD has faster decay with time but a higher error floor.\nTime\n‚Ä¢ -‚Ä¢ Fully Sync\nWall clock time\nK=4 Batch Sync\nDuOa et al. Slow and stale gradients can win the race: errorrunJme tradeoffs in distributed SGD. 2018\nSynchronous\nAsync SGD\nReduc_on over Gradients\nTo synchronize gradients of N learners, a reduction operation needs to be performed\n87\nSend\nGPU 2\nGPU 4\nReceive\nReceive\nGPU 1\nGPU 0\nSend\nReduc_on Topologies\nSend\nGPU 4\nReceive\nParameter server: single reducer\nGPU 2\nSUM (Reduce operation) performed at PS\nReceive\nSend\nReceive\nGPU 3\nGPU 1\nReceive\nSend\nGPU O\nSend\nGPUs arranged in a logical Ring (aka bucket) : all are reducers\nSUM (Reduce operation) performed at all nodes\nEach node has a left neighbor and a right neighbor\nNode only sends data to its right neighbor, and only receives data from its left neighbor\n88\nGPU O\nGPU 0\nGPU 1\nGPU 1\nGPU 2\nGPU 2\nGPU 3\nGPU 3\nGPU 4\nGPU 4\nArrays Being Summed b2+b,+bg+be+bo CatCz+CatCptC, datdg+dotd,+de eptente, teztez\na, +apta,+az+a4\nao a, taptaz+a3+a4\nCo ba+b,+bg+ba+bo Cz+G2+G4+Co+C, de+dg+do+d,+d2 estente, +e2+–µ3\nay a, taptaz+az+a4\nba+b,+bg+ba+bo Cz+C2+C4+Co+C, de+dg+do+d,+d2 estente,+e2+e3\n22\nb2\nAll-Reduce\nb4\na, taptartaz+a4\nb2+b,+b3+b4+bo G3+C2+C4+Go+G,\nPartitioning of an array into N chunks\nFinal state after all allgather transfers\nde+dz+do+d,+d2 eptente,+e2+e3\n89\nGPU O\nGPU 1\nGPU 2\nRing All-Reduce\nGPU 3\nGPU 4\n–°–∑\n¬∑ Two step algorithm:\nda\nScatter-reduce\nGPUs exchange data such that every GPU ends up with a chunk of the final result\nAllgather\nGPUs exchange chunks from scatter-reduce such that all GPUs end up with the complete final result.\nArrays Being Summed do\nd,\n90\nGPU 0\nGPU O\nGPU O\nGPU O\nGPU 1\nGPU 1\nGPU 1\nGPU 1\nGPU 2\nGPU 2\nGPU 2\nGPU 2\nGPU 3\nGPU 3\nGPU 3\nGPU 3\nGPU 4\nGPU 4\nArrays Being Summed\nArrays Being Summed bo\nbo\nCo bo\nCo do\nCz+G2+C4+G0\nda+dy+do bo\nCo dy+dy+do\nb, b,\nb, b2\nbz+b, b2+b,\nb,+b, b,+b, +b3\nC,\nC,\nC,\nC,\nC2\nC2\nC3+62\ng3+62\naol ao\nay a, +ao\na, +ao a, +ao\na, tapta,\n22\na, +a, +a2\nag a, tapta,+ag\nGPU 4\ndo d,\nd, dy\nda+dz+do+d, de\nde dg\ndg b,+b, +b3\nC3 +62\nRing All-Reduce: Scacer-Reduce Step\nGPU 4\n¬Æ+¬Æ4\neg+e4\n¬©o+e4\neg+eg+e, e,\ne, eptente, +e2\n–õ\n91\nGPU 0\nGPU 1\na, +ao ba+b,+b3+b4+bo\nb, da+da+do\nda+dg+do+dy\nRing All-Reduce: End of Scacer-Reduce Step\nb2+b, +b3\nGPU 3\nGPU 4\na, tag ta, +ag\n03+02\na, tap+az+az+a\nb2+b, +b3+b4\nC3+62+64\nFinal state after all scatter-reduce transfers\n‚Ç¨4\nCz+C2+64+60\nHow many iterations in scatter-reduce step with N GPUs ?\n92\nGPU\nSend\nGPU 0\nChunk 1\nReceive b2+b,+b3+b4+bo\nChunk O\nGPU 1\na, +ao\nChunk 2 Chunk 1\nRing All-Reduce: What to do next ?\nChunk 4 Chunk 3\nGPU 3\nGPU 4\na, tag ta, +ag ba+b,+b3\nC3+62\neptente, tez+e3\na, tap+az+az+a4\nba+b, +b3+ba\nCz+C2+64\nFinal state after all scatter-reduce transfers\n‚Ç¨4\nChunk 0 Chunk 4\nb,\n1\n2\n3\n4\nCz+C2+04+60\nda+da+do da+da+do+d,\neo+e4\neotente,\n93\nGPU 0\nGPU 0\nGPU 1\nGPU 1\nGPU 2\nGPU 2\nGPU 3\nGPU 3\nGPU 4\nGPU 4\nGPU 0\nGPU O\nGPU 1\nGPU 1\nGPU 2\nGPU 2\nGPU 3\nGPU 3\nGPU 4\nGPU 4\na, tao taz+az+a4\na, +ao a, +ao\na, +ao+a2\na, +ap+a2\nb2+b, +bz+b,+bo b2+b,+b3+bg+bo\nb2+b, +b3+b,+bo b,\nb2+b, bz+b,\nd,+dz+do da+dy+do\nda+dg+do+d, dy+dy+do+d,\nds+dg+do+d, +d2\nde+d+do+d, +d2\neo+e4\n¬Æ+‚Ç¥4\neoteq+e, eptente,\neptez+e, +e2\nCz+62+C4+Co\nC3+C2+C4+C0\nC3+02+G4+60+61\nC3+62+C,+Go+C,\nCz+C2+C4+Go+C,\nRing All-Reduce: AllGather Step\na, tap+az+az+a4\na, +ao+az+ag+a4\nb2+b, +b3+b4\nbz+b, +bg+ba\nCz+C2+C4\nd, +d, eptente, +e2+e3\nCz+C2+C4\na, +ag+az+az+a,\nb2+b, +bg+b,+bo\nC3+C,+C,+C0\nde+dg+do+d, +d2\nepte,+e, +e2+@3\na, tap+az+az+a4\nbz+b, +bg+b, +bo\nde+dz+do+d,\neptente, te2+e3\na, +ap+a, +a+a4\nbz+b, +bg+be+bo\nC+C2+C, +Go+C,\nde+dg+do+d, +d2\n@ote4+e, +e2\na, tag+a2+a3\nb2+b, +bg+b,+bo\nCz+62+C4+Go+C,\ndy+dg+do+d, +d2\neptente, tez+ez\na, taptaztag+a4\nb2+b, +b3+04\nde+dg+do+d, +d2\neptente, +ez+e3\na, +ao+a2+ag+a4\nbz+b, +b3+b4+bo\nCz+C2+C4+Co\nd,+dy+do\neotente, +e2+e3\na, tap+az+az+a4\nbatb,+b3+ba+bo\nC3+C2+C4+G0+C,\nda+dg+do+d,\neote4+e,\na, tao+a2\nb2+b, +b3+b4+bo\nC3+62+G4+C0+C,\nds+dz+do+d, +d2\neotente, +e2\na, +ao+a2+az\nbz+b, +b3\nCz+G2+G4+Gg+C,\nds+dy+do+d, +d2\neptente, +e2+e3\na, +ap+a,+–∞–∑+–∞–¥\nb2+b, +b3+b4\nC3+C2 +C4\nds+dz+do+d,+d2\n@p+@4+@, +@2+83\n94\nGPU 0\nGPU 1\nGPU 2\na, taptaz+az+a4\nb2+b,+b3+b4+bo a,taptaz+az+ay ba+b,+ba+ba+bo\nC3+62+64+60+61\nCz+G2+G4+Gp+C1\nd4+dg+do+d,+d2 ¬Æ+@4+@,+@2+¬Æ3\ndg+dg+do+dy+d2 @otente,+e2+e3\nRing All-Reduce: End of AllGather Step a,taptaz+ag+a4 ba+b,+bg+ba+bo Cz+G2+G4+G0+C1 ds+dg+do+d,+d2 eptente,+e2+e3\nGPU 3\nGPU 4\nCz+G2+C4+G+C, d+dg+d,+d,+d2¬Æ+¬©,+@,+@2+¬Æ3\na, taptaz+az+ad ba+b,+bg+ba+bo\na,taptaz+az+a4\nba+b,+b3+ba+bo Gz+C2+C4+Cp+C, da+dg+do+d,+d2 estente, +e2+e3\nFinal state after all allgather transfers\nHow many iterations in allgather step with N GPUs ?\n95\nParameter Server (PS) vs Ring All-Reduce: Communica_on Cost\nP: number of processes  N: total number of model parameters\nPS (centralized reduce)\nAmount of data sent to PS by (P-1) learner processes: N(P-1)\nAfter reduce, PS sends back updated parameters to each learner\nAmount of data sent by PS to learners: N(P-1)\nTotal communication cost at PS process is proportional to 2N(P-1)\nRing All-Reduce (decentralized reduce)\nScatter-reduce: Each process sends N/P amount of data to (P-1) learners\nTotal amount sent (per process): N(P-1)/P\nAllGather: Each process again sends N/P amount of data to (P-1) learners\nTotal communication cost per process is 2N(P-1)/P\nPS communication cost is proportional to P whereas ring all-reduce cost is practically independent of P for large P (ratio (P-1)/P tends to 1 for large P)\nWhich scheme is more bandwidth efficient ?\nNote that both PS and Ring all-reduce involve synchronous parameter updates\n96\nAll-Reduce applied to Deep Learning\nBackpropagaaon computes gradients starang from the output layer and moving towards in the input layer\nGradients for output layers are available earlier than inner layers\nStart all reduce on the output layer parameters while other gradients are being computed\nOverlay of communicaaon and local compute\n97\nDistributed Deep Learning Benchmarking Methodology\nSpeedup\nScaling efficiency\nAccuracy and end-to-end training ame\nNeural network\nDeep learning framework\nGPU type\nCommunicaaon overhead\nSpeedup (throughput) with n machines = n x Scaling efficiency with n machines\n98\nScaling efficiency\nScaling efficiency: ratio between the run time of one iteration on a single GPU and the run time of one iteration when distributed over N GPUs. Why is this ratio a measure of scaling efficiency ?\nOne can satisfy any given scaling efficiency for any neural network by increasing the batch size and reducing communication overhead\nToo big a batch size will result in converging to an unacceptable accuracy or no convergence at all\nA high scaling efficiency without being backed up by convergence to a good accuracy and end to end training time is meaningless\n99\nImagenet1K/ResNet50 Training at Scale\nCho et al achieved highest scaling efficiency; Goyal et al and Ying et al achieved highest accuracy\n100\nmultiple rings in horizontal and vertical orientations.\nRING Vo\nRING HO\n2-D Torus Topology for inter-gpu communication\nmultiple rings in horizontal and vertical orientations.\n(O,Y-1) -\nRING VI\nRING Vx-1\n(X-1,Y-1)\n101\nI. Reduce-Scatter in the horizontal direction\nAGPUO\n2\n3\n10\n11\n4\n12\n5\n13\nAdd\nAdd\nGPUT\n6\n7\nGPU32\n14\n15\n8\n16\n6\n22\nII. All-Reduce in the vertical direction\nGPUO\n8\n3\nAdd\nGPU2\n24\n11\n2-D Torus all-reduce\nIII. All-Gather in the horizontal direction\n4\n5\n12\n13\nIV. Completed\n2D-Torus all-reduce steps of a 4-GPU cluster, arranged in 2x2 grid\n28\n28\n32\n3\nGPU2\n32\n11\n4\n12\n5\n6\n36\nGPU3\n40\n28\n32 36\n13\n14\n36\n40\n28\nGPU2\n32\n36\n40\n28\nGPUI\n6\n10\nAdd\nGPU3\n14\n26\n12\n28\nGPU1\n32 36 40\nGPU3\n40\n36\n40\nhttps://arxiv.org/pdf/\nhttps://arxiv.org/pdf/1811.05233.pdf\n28\n32\n1\n9\nCopy\nImages per second\n160000\n140000\n120000\n100000\n80000\nHigh\nBandwidth\n60000\nMemory\n40000\n20000\nTensor Processing Units (TPUs)\nNumber of TPU v2 chios\nTPU:  application specific integrated circuits to accelerate machine learning workload\nTPU pod: multiple TPU chips connected to each other over a dedicated high-speed network connection\nhttps://cloud.google.com/tpu/docs/systemarchitecture\nTPU v2 pod for ResNet-50: linearly scalable\nNumber of TPU v2 chips\n*\nObserved\nPerfect\nTensorCore\nScalar Unit\nVector Unit\nMatrix\nMultiplication\nUnit\nMatrix\nMultiplication\nUnit\nTPU v5e chip\nA TensorCore has four matrix-multiply units (MXUs), a vector unit, and a scalar unit https://cloud.google.com/tpu/docs/v5e\n103\n$100.00\n$75.00\n$50.00\n$25.00\n$0.00\nResNet-50 Training Cost Comparison\n8 V100 GPUs\n27 times faster training\nTPUs vs GPUs Performance\n1 full Cloud TPU v2\nPod training duration:\n7.9 minutes for 90 epochs\n256 TPUs v\n256 TPUs v2 chips\nFull Cloud TPU v2 Pod\nGoogle Cloud VM with 8 100 GPUs\n104\n1-Chip VM\nChipo\nChip1\nTPU host in a v5e\n4-Chip VM\nChip4\nChip5\nTPU VM on Google Cloud\nChip2\nChip3\nChipo\nChip7\nCPUO\n'Cle\nNUMA O\nA TPU host is a VM that runs on a physical computer connected to TPU hardware. TPU workloads can use one or more host.\nTutorial on using Google Cloud TPU VM: Google Cloud Quickstart\nCPU1\nPC/e\nNCCL\nNvidia Common Communications Library\nNCCL implements optimized multi-GPU and multi-node communication primitives for NVIDIA gpus and networking\nNCCL provides routines such as all-gather, all-reduce, broadcast, reduce, reduce-scatter as well as point-to-point send and receive\nCommunication primitive are optimized to achieve high bandwidth and low latency over PCIe and NVLink high-speed interconnects within a node and over NVIDIA Mellanox Network across nodes\nPrepare for Lecture 2\nAccess to compute cluster\nSet up you  NYU HPC access; instructions coming soon\nFirst home-work posted on 09/12\n107\nBackup material\n108\nRapid evolution of new models\nGPT-4o : text, audio, images\nClaude 3.5 Sonnet\nLLaMa 3\nDalle 2\nGemini 1.5\n109\nAI at US Open\nhttps://www.ibm.com/case-studies/usopen\nGenerative AI models for generating content\nIBM Granite foundation models\nIBM watsonX AI and data platform built for business\nwatsonX.data: to connect and curate the USTA's trusted data sources\nFoundation models were trained to translate tennis data into cogent descriptions\nsummarizing entire matches in the case of Match Reports\ngenerating sentences that describe the action in highlight reels for AI Commentary\n'Foundation models are incredibly powerful and are ushering in a new age of generative AI, But to generate meaningful business outcomes, they need to be trained on high-quality data and develop domain expertise. And that's why an organization's proprietary data is the key differentiator when it comes to AI.'\nShannon Miller, IBM Consulting\n110\nof a model\nExample: Predict y from x\nLINEAR SIMPLIFICATION\nTRUE MODEL\nBias of a model\nx=2\nx\n‚Ä¢ First impression: Polynomial model such as y = wot wat\nW2x? + w323 + wax is \"better\" than linear model y = wo +\nW1X.\n-\n111\nDifferent Training Data Sets with Five Points\nLINEAR SIMPLIFICATION\nTRUE MODEL\nx: = 2\nSAMPLE FIVE TRAINING POINTS\nx=2\nSAMPLE FIVE TRAINING POINTS\nSAMPLE FIVE TRAINING POINTS\nx=2\nLINEAR PREDICTION AT x=2\n*=2 POLYNOMIAL PREDICTION AT *=2\nx=2\n‚Ä¢ Zero error on training data but wildly varying predictions of\n112\nObservations\n‚Ä¢ The higher-order model is more complex than the linear\nmodel and has less bias.\n- But it has more parameters.\nFor a small training data set, the learned parameters will\nbe more sensitive to the nuances of that data set.\n- Different training data sets will provide different predic-\ntions for y at a particular x.\n- This variation is referred to as model variance.\n‚Ä¢ Neural networks are inherently low-bias and high-variance\nlearners ‚Üí Need ways of handling complexity.\n113\nBias-Variance Trade-off: Setup\n‚Ä¢ Imagine you are given the true distribution B of training data\n(including labels).\nYou have a principled way of sampling data sets D ~ B from the training distribution.\nImagine you create an infinite number of training data sets (and trained models) by repeated sampling.\nYou have a fixed set T of unlabeled test instances. - The test set T does not change over different training\ndata sets.\n- Compute prediction of each instance in T for each trained\nmodel.\n114\nInformal Definition of Bias\n‚Ä¢ Compute averaged prediction of each test instance a over different training models g(x, D).\n‚Ä¢ Averaged prediction of test instance will be different from\ntrue (unknown) model f(x).\n‚Ä¢ Difference between (averaged) 9(x, D) and f(x) caused by\nerroneous assumptions/simplifications in modeling ‚Üí Bias\n- Example: Linear simplification to polynomial model causes bias.\nIf the true (unknown) model f(x) were an order-4 poly-\nnomial, and we used any polynomial of order-4 or greater in g(x, D), bias would be 0.\n115\nInformal Definition of Variance\n‚Ä¢ The value g(x, D) will vary with D for fixed x.\n- The prediction of the same test instance will be different\nover different trained models.\nAll these predictions cannot be simultaneously correct ‚Üí\nVariation contributes to error\n‚Ä¢ Variance of g(x, D) over different training data sets ‚Üí Model\nVariance\nExample: Linear model will have low variance.\nHigher-order model will have high variance.\n116\nBias-Variance Equation\n‚Ä¢ Let E[MSE] be the expected mean-squared error of the fixed\nset of test instances over different samples of training data\nsets.\nE[MSE] = Bias? + Variance + Noise (1) - In linear models, the bias component will contribute more to E[MSE].\ntribute more to E[MSE].\n- In polynomial models, the variance component will con-\nWe have a trade-off, when it comes to choosing model complexity!\n117\nLearning rate and Batch size relationship\n'Noise scale' in stochastic gradient descent (Smith et al 2017)\nThere is an optimum noise scale g which maximizes the test set accuracy (at constant learning rate)\nIntroduces an optimal batch size proportional to the learning rate when B ‚â™ N\nIncreasing batch size will have the same effect as decreasing learning rate\nAchieves near-identical model performance on the test set with the same number of training epochs but significantly fewer parameter updates\nTraining cross-entropy\n2.0\n101\n1.5\nLearning rate\n10?\nLearning rate decrease Vs Batch size increase Decaying learning rate\n10¬™\n0.0\n10'\nBatch size\nTest set accuracy\n10*\n10‚Ç¥\n50\n100\nNumber of epochs\n150\nDecaying learning rate\nHybrid\nIncreasing batch size\n50\n100\nNumber of epochs\n150\n200\n200\n0.90\n0.85\n0.80\n0.75\n0\n50\n50\n100\nNumber of epochs\n150|\n200\nDecaying learning rate\nHybrid\nIncreasing batch size\n100\nNumber of epochs\n150\n200\nDecaying learning rate\nHybrid\nIncreasing batch size\n119\nBatch normalization\nInternal covariance shift - change in the distribution of network activations due to change in network parameters during training\nIdea is to reduce internal covariance shift by applying normalization to inputs of each layer\nAchieve fix distribution of inputs at each layer\nNormalization for each training mini-batch .\nBatch normalization enables training with larger learning rates\nReduces the dependence of gradients on the scale of the parameters\nFaster convergence and better generalization\n120\nInput: Values of x over a mini-batch: B = {x1...m};\nParameters to be learned: v, B\nOutput: {yi = BNy, (xi)}\nm\nExi\nMBI\nm\nBatch normalization\nm\ni=1\n// mini-batch mean\nWhy this step ?\n121\nBest practices when benchmarking distributed deep learning systems\nSystems under comparison should train to same accuracy\nAccuracy should be reported on sufficiently large test set\nCompute to communication ratio can vary widely for different neural networks. Using a neural network with high compute to communication ratio can hide the ills of an inferior distributed Deep Learning system.\na sub-optimal communication algorithm or low bandwidth interconnect will not matter that much\nComputation time for one Deep Learning iteration can vary by up to 50% when different Deep Learning frameworks are being used. This increases the compute to communication ratio and gives the inferior distributed Deep Learning system an unfair uplift to the scaling efficiency.\n122\nBest practices when benchmarking distributed deep learning systems\nA slower GPU increases the compute to communication ratio and again gives the inferior distributed Deep Learning system an unfair uplift to the scaling efficiency.\nNvidia P100 GPUs are approximately 3X faster than Nvidia K40 GPUs.\nWhen evaluating the communication algorithm and the interconnect capability of a Deep Learning system, it is important to use a high performance GPU.\nCommunication overhead is the run time of one iteration when distributed over N GPUs minus the run time of one iteration on a single GPU.\nIncludes the communication latency and the time it takes to send the message (gradients) among the GPUs.\nCommunication overhead gives an indication of the quality of the communication algorithm and the interconnect bandwidth.\n123\nDL Pipelining\nPipelining approach:\nSplit layers among compute engines\nEach minibatch b (or sample s) goes from one compute engine to the next one: no need to wait for next one to exit the pipeline\nIs a form of Model Parallelism\nPipelining performance\nIdeal pipelining speedup (number of pipeline stages)\nùëÜ_ùë°ùëñùëöùëí ùë†ùë°ùëéùëîùëí\tùë°ùëñùëöùëí = ùë°ùëñùëöùëí\tùë§ùëñùë°‚Ñéùëúùë¢ùë°\tùëùùëñùëùùëíùëôùëñùëõùëí ùëõùë¢ùëöùëèùëíùëü\tùëúùëì\tùëùùëñùëùùëíùëôùëñùëõùëí\tùë†ùë°ùëéùëîùëíùë†\nSpeedup is higher for deeper networks\nIdeal pipelining never reached because of 'bubbles' that cause idle CPUs\nSGD pipeline bubble:\nBefore weights update, all batches need to have completed forward (otherwise accept staleness )\ntime\nNon-pipelined execution\nùë°\n&\nùë°\n$\nùë°\n'\nùë°\n(\nùë°\n)\nùë°\n*\nùë°\n+\nùë°\n,\nGPU\n1\n(L1)\nb\n2\nb1\nGPU\n2\n(L2)\nb\n2\nb1\nGPU\n3\n(L3)\nb\n2\nb1\nGPU\n4\n(L4)\nb\n2\nb1\nL1\nL2\nL3\nL4\nPipelined execution\nùë°\n&\nùë°\n$\nùë°\n'\nùë°\n(\nùë°\n)\nùë°\n*\nùë°\n+\nùë°\n,\nGPU\n1\n(L1)\nb\n8\nb\n7\nb\n6\nb\n5\nb4\nb3\nb2\nb1\nGPU\n2\n(L2)\nb\n8\nb\n7\nb\n6\nb5\nb4\nb3\nb2\nGPU\n3\n(L3)\nb\n8\nb\n7\nb6\nb5\nb4\nb3\nGPU\n4\n(L4)\nb\n8\nb7\nb6\nb5\nb4\nL1\nL2\nL3\nL4\ntime\nHPML\n124",
      "metadata": {
        "chunk_index": 0,
        "source_type": "attachment",
        "message_id": "19aadaf0f535cdc9",
        "from": "Abhinav Batra <ab12615@nyu.edu>",
        "to": [],
        "subject": "Test email wih different attachments",
        "date": "Sat, 22 Nov 2025 17:28:07 -0500",
        "timestamp": 1763850487,
        "token_count": 14558,
        "attachment_name": "Lecture-1-nyu.pdf",
        "attachment_type": "pdf"
      }
    },
    {
      "chunk_id": "19aadaf0f535cdc9_att_19a2beedbec581a4_2026 BME-CAIR Research Project Descriptions_pdf_0_958aed49",
      "text": "NSF\nCHIN\nWake Forest University School of Medicine 28 50 10 28 32 32 100 100 1E0 Canvolutional Lever 2l Max-pooling Ma-poolina layer 21 Feature layer SOGEGAGTCA AATAT CAT GC G\nInput laver\nCeewolution all layer 1\n2026 Research Project Descriptions\nSummer Research Internship Program\nfor Undergraduate & MS Graduate Students\nNSF\nIII\nNAID\nCENTER FOR ARTIFICIAL INTELLIGENCE RESEARCH\nA III\nNIH\n40+ Projects in Biomedical Engineering, Biomedical Informatics, AI, & more!\nlaver 1\nveron. Sluures mcorpoldle a lange ul musculoskeletal metous, moluumo puted tomography (QCT) of the hip and spine, and high-resolution peripheral\nWake Forest University outed tomography (HRpQCT) of the ankle and wrist. K\n1) review the literature on weight loss oss and techniques for measuring bone\nSchool of Medicine G\nand HRpQCT, 2) form a hypothesis to\nProject 1 - Summer 2026\nnd 3) experimentally test the hypothesis\nIntervening to Mitigate Weight Loss Associated Bone Loss\nIdentification of intervention strategies to minimize weight loss associated bone loss among middleaged and older adults is needed. Two 12-month NIH clinical trials were recently funded to: 1) test whether  bisphosphonate  therapy  can  minimize  bone  and  muscle  loss  associated  with  bariatric surgery  among 120 sleeve gastrectomy patients, and 2) compare the independent and combined effects  of  progressive  resistance  training  plus  bone  loading  exercises  and  bisphosphonate  use  on measures of bone density, quality, and turnover in 308 older adults who are undergoing a dietary weight  loss  intervention.  Studies  incorporate  a  range  of  musculoskeletal  methods,  including quantitative  computed  tomography  (QCT)  of  the  hip  and  spine,  and  high-resolution  peripheral quantitative computed tomography (HRpQCT) of the ankle and wrist.\nProfessor\nThe student will: 1) review the literature on weight loss associated bone loss and techniques for measuring bone health  using  QCT  and  HRpQCT,  2)  form  a  hypothesis  to test  the  effect  of  skeletal  loading  and  bisphosphonate interventions on CT-derived bone outcome such as bone mineral density (BMD), cortical thickness, bone strength, or fracture risk, and 3) experimentally test the hypothesis by  applying  learned  CT  analysis  and  finite  element  (FE) modeling techniques to collect, analyze, and draw conclusions from the resulting bone outcome data.\nAshley Weaver, PhD\nKristen Beavers, PhD\nProfessor Gerontology & Geriatric Medicine Wake Forest School of Medicine Winston-Salem, NC\nhttps://school.wakehealth.edu/faculty/b/ kristen-marie-beavers\nProfessor Biomedical Engineering Wake Forest School of Medicine Winston-Salem, NC\nAshley Anne Weaver, PhD | Wake Forest University School of Medicine\nV\n2x\nWake Forest University\nSchool of Medicine\nProject 2 - Summer 2026\nIn-Situ Bioprinting Path Planning in Augmented Reality\nIn-Situ Minimally Invasive Surgical Robotic Bioprinting\nBioprinting has been well established as a method of developing biomimetic structures for tissue engineering to create scaffolds, constructs, and organoids. The  process  of bioprinting using  Cartesian  and  multi-axis  additive manufacturing  allows  for  a  synergistic pairing with surgical robotics. This project aims to develop an in-situ laparoscopic  bioprinting  system  through the  research  of  supporting  technologies in real-time scanning and sensing, motion compensation mechatronics, and augmented reality surgical planning and control.\nWe are creating a printing platform that can scan organic surfaces and adapt the extruder  height  and  flow  rate  within acceptable tolerances is needed to overcome in-situ printing challenges. We are  looking  for  help  in  control  systems, tool  design,  biomaterials,  software  and augmented reality.\nPhilip Brown, PhD\nAssociate Professor, Biomedical Engineering Director, Translational Engineering and Design Core\nOffice: 336-716-0945\nphibrown@wakehealth.edu www.linkedin.com/in/philip-brown-71a24553\nmanulaculmo, anlu prouuctor amoud a vallety ur matellar ane prmus lectoroges.\nWake Forest University\nSchool of Medicine\nModulus\nCloud\nModel\nManufacture\nProject 3 - Summer 2026\nMechanically Matched Patient Specific Bone Surrogates\nRecent advancements in super resolution artificial intelligence, additive manufacturing, and highperformance  computing  present  unique  opportunities  in  the  space  of  medical  device  design  for patient  specific  implants  and  patient/population  specific  mechanical  surrogate  bones.  We  are working  to  create biomechanically  accurate subject  specific 3D-printed  bone  surrogates  from clinical resolution CT scans. We are working to create and validate workflows for image analysis, mechanical analysis and interpretations, design from mechanical properties for additive manufacturing, and production through a variety of material and printing technologies.\nAssociate Professor, Biomedical Engineering\nDirector, Translational Engineering and Design Core\nOffice: 336-716-0945\nphibrown@wakehealth.edu\nwww.linkedin.com/in/philip-brown-71a24553\nPhilip Brown, PhD\nAssociate Professor, Biomedical Engineering Director, Translational Engineering and Design Core\nOffice: 336-716-0945\nphibrown@wakehealth.edu www.linkedin.com/in/philip-brown-71a24553\nFlexion - Etension (mm)\n20\n15\n10|\n-15|\nWake Forest University\nSchool of Medicine\nProject 4 - Summer 2026\nFull Field Spinal Characterization Methodology Development\nLateral Bending (mm)\nThe widely accepted method for evaluating spinal biomechanics developed  by  Panjabi  et  al  has  been  adopted  into  standards such as ASTM F2077-22 to validate spinal implants. This method involves applying a pure Cartesian moment to a spinal segment or a functional spinal unit (FSU) in each physiologic plane, then measuring  the  resulting  range  of  motion  (ROM),  loading  and unloading stiffness, hysteresis, and neutral zone (NZ) behavior. While  planar  moment  testing  is  a  standardized  and  powerful tool,  it  leaves  the  spinal  motion-loading  space  in-  between planes  untested  and  unknown.  Adding  more  simultaneous dimensions of  loading  in  a  full-field  multi-planar  methodology will  lead  to  deeper  insight  into  the  complex  physiological behavior of the spine in various surgical interventions.\nTo  address  this  gap,  we  propose  a  novel  testing  protocol  that uses  six-degree-of-freedom  trajectories  to  produce  complex motion paths which mapping the spine's full-field  multi-planar behavior. This exploration enables multidimensional visualization  of  the spine's bending  stiffness  in  all  directions within its physiological limits. The objective of this study was to debut complex multi-planar spinal testing, explore visualization strategies,  and  identify  spinal  behavior  insights  gained  relative to traditional testing.\nPhilip Brown, PhD\nAssociate Professor, Biomedical Engineering Director, Translational Engineering and Design Core\nOffice: 336-716-0945\nphibrown@wakehealth.edu www.linkedin.com/in/philip-brown-71a24553\nCS\n2S\n1\nle\nCAPLA\nWake Forest University School of Medicine\nProject 5 - Summer 2026\nAssessment of Pedestrian Crash Protection Systems using RealWorld Pedestrian Crash Data in CARLA\nModern vehicles are equipped with advanced safety features including pedestrian crash avoidance but there are still numerous scenarios  where  these  systems  fail  to  avoid crashes.\nCARLA  is  an  open-source  tool  developed  to support the development, training, and validation of autonomous driving systems.\nThe  project  objective  is  to  use  this  tool  to assess  existing  and  new  safety  systems  by reconstructing real-world pedestrian crashes.\nThe student will help create pedestrian crash scenarios and test different sensor suites in a virtual environment.\nStudent will build skills in pythonprogramming, crash data analysis, biomechanics, and injury analysis.\nKaran Devane, PhD\nAssistant Professor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave\nWinston-Salem, NC 27101\nhttps://school.wakehealth.edu/faculty/d/karan-shamrao-devane\nIMPACT ZONE\nWake Forest University School of Medicine SKID MARKS\nDEBRIS FIELD.\nProject 6 - Summer 2026\n(80%)\nDevelopment of Machine Learning Model for Predicting Pedestrian Injuries using Real-World Crash Databases\nImages, vehicle parameters, crash details, and pedestrian injury data from the crash databases will be used to train and test a machine learning model that will be used to predict pedestrian injuries.\nStudent will be parsing the databases to collect all the required data, preprocess it, and build an injury prediction model.\nStudent  will  build  skills  in  python-programming,  crash  data  analysis,  biomechanics,  and  injury analysis.\nStudent will get to interact with multidisciplinary team of experts.\nSchool of Biomedical Engineering and Sciences https://school.wakehealth.edu/faculty/d/karan-shamrao-devane\n575 N. Patterson Ave\nWinston-Salem, NC 27101\nKaran Devane, PhD\nAssistant Professor, Biomedical Engineering\nVT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nhttps://school.wakehealth.edu/faculty/d/karan-shamrao-devane\n/e\n1\nWake Forest University\nSchool of Medicine\nProject 7 - Summer 2026\nHuman Body Model Development for Trauma Research\nComputational modeling is a growing  component of injury biomechanics and trauma  research. This project  is  a  multi-center  effort    developing  a  next  generation  set  of  human  body    finite  element models for enhanced injury  prediction and prevention systems. The student  will be responsible for assisting in model  development tasks including scaling, postural  adjustment, meshing, and contact algorithm  development. Responsibilities will also include  reporting FEA model analysis and results, running analyses on distributed computing environments, simulating validation procedures, performing literature reviews, and reporting  related research efforts through written and oral  status updates.  The  student(s)  will  gain    valuable  experience  in  fields  of  trauma    research,  computer modeling, and injury  biomechanics.\nThis  research effort will  be  in  the  Center  for  Injury Biomechanics (CIB) and you will have the opportunity to work on a range of projects centered around safety. The human is at the center of all the research we do. We operate in the fields of mobility safety, data analytics including database and medical  image  analysis,  military  countermeasures, and  sports  biomechanics.  The  research  at  the  CIB combines experimental testing, computational modeling, and analytics to investigate human injury biomechanics\nScott Gayzik, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nwww.CIB.vt.edu\n/e\n1\n1.0\nWake Forest University\nSchool of Medicine\nProject 8 - Summer 2026\nStandardizing Methods for Virtual Assessment in Human Body Models\nHuman body models (HBMs) have gained prominence in biomechanics literature over  the last two decades, but there is little information available regarding the standardization of model positioning and injury assessment. It is  well understood that deviations in initial positioning of human models can lead to deviations in outcomes for otherwise identical crash simulations, yet this effect is not well quantified. This project focuses on developing best practices (BPs) for simulation-based repositioning,  gravity-    settling,  belting,  pre-test  posture  reporting  and  injury  prediction  using computational  human  body  models.  Your  research  will  be  on  the  cutting  edge  of  this  digital transformation of the regulatory space!\nThis  research effort will  be  in  the  Center  for  Injury Biomechanics (CIB) and you will have the opportunity to work on a range of projects centered around safety. The human is at the center of all the research we do. We operate in the fields of mobility safety, data analytics including database and medical  image  analysis,  military  countermeasures, and  sports  biomechanics.  The  research  at  the  CIB combines experimental testing, computational modeling, and analytics to investigate human injury biomechanics.\nScott Gayzik, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nwww.CIB.vt.edu\n/e\n1\nWake Forest University\nSchool of Medicine\nProject 9 - Summer 2026\nPhysics-based Finite Element Analysis for Injury Criteria Using Human Surrogates\nThe  objective  of  this  research  is  to  develop  and  validate  a  physics-based  finite  element  model(s) (ovine and caprine) to study behind armor blunt trauma (BABT).  These models will be an important tool for evaluating countermeasures and developing  computational injury criteria to better protect service members. The models will be used to provide insight and guidance on the risk of skeletal and soft  tissue  injuries  including  the    development  of  injury  criteria  for  rib,  pulmonary  and  limited vascular  and  peripheral  organ    injury  from  BABT.  The  proposed  project  is  the  first  of  its  kind  to develop ovine and caprine  FEA models for use in the study of BABT. Specifically, the models will be used to develop  finite element based BABT injury criteria.\nThis  research effort will  be  in  the  Center  for  Injury Biomechanics (CIB) and you will have the opportunity to work on a range of projects centered around safety. The human is at the center of all the research we do. We operate in the fields of mobility safety, data analytics including database and medical  image  analysis,  military  countermeasures, and  sports  biomechanics.  The  research  at  the  CIB combines experimental testing, computational modeling, and analytics to investigate human injury biomechanics.\nScott Gayzik, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nwww.CIB.vt.edu\n/e\n1\nWake Forest University School of Medicine 14272 HIC 14272. B/C\nProject 10 - Summer 2026\nDevelopment of Signal Analysis Tools for a National Crash Database\nThe key objective of this effort is to modernize the United States federal government's Vehicle Safety Research Signal Analysis Tools. Our fundamental motivation for this work is to 1. Modernize the code offered by creating a fully web-based tool and 2. Update the existing code to interact with a Crash Test  Database  that  already  exists  online.  The  approach  we  will  take  involves  a  ground  up reconstruction of the underlying code. The student will assist by helping build the code and running calculations of fundamental biomechanical measures used in kinematic, kinetic and injury assessments. The project is sponsored by the National Highway Traffic Safety Administration.  This is an opportunity to see your work be used by hundreds or even thousands of users worldwide.\nThe  project  will  marry  the  fields  of  web-based  software  development  and  biomechanics  and represents an exciting opportunity for engineers interested in both domains. The skills and training a student  will  develop  on  for  this  project  will  be  highly  translatable  for  careers  in  biomechanics  or software development.\nThis  research effort will  be  in  the  Center  for  Injury Biomechanics (CIB) and you will have the opportunity to work on a range of projects centered around safety. The human is at the center of all the research we do. We operate in the fields of mobility safety, data analytics including database and medical  image  analysis,  military  countermeasures, and  sports  biomechanics.  The  research  at  the  CIB combines experimental testing, computational modeling, and analytics to investigate human injury biomechanics.\nScott Gayzik, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nwww.CIB.vt.edu\nimplementation, and/or delivery of quantitative results.\nWake Forest University School of Medicine In response, our laboratory has applied a molecular detection strategy using the solid-state nanopore platform, which is able to detect and size HA electrically\nand with tremendous sensitivity. Here, we will apply our\nassay to probe the HA content of plasma derived from\nProject 11 - Summer 2026\nMolecular Detection and Analysis of Trauma Bioindicators\nHyaluronan (or hyaluronic acid, HA) is a  key  linear  sugar that  is found  in  all  physiological  fluids  and tissues,  where  variation  in  its  composition  can  either  result  from  or  be  a  direct  cause  of  disease emergence. While changes in net HA abundance in biofluids can be probed conventionally, this metric ignores a critical size-function relationship in which high- and low-molecular weight (MW) HA exhibit contrasting effects on inflammation, angiogenesis, cell motility, and more. Consequently, determination  of  both  HA  abundance and size  distribution  is  essential.  However,  many  important physiological  systems  contain  small  total  amounts  of  HA  and  technologies  for  comprehensive assessment have critical limitations in sensitivity as well as challenges in dynamic range, cost, ease of implementation, and/or delivery of quantitative results.\nIn response, our laboratory has applied a  molecular detection strategy using the solid-state nanopore platform,  which  is  able  to  detect  and  size  HA  electrically and with tremendous sensitivity. Here, we will  apply our assay  to  probe  the  HA  content  of  plasma  derived  from trauma patients. As a central goal of this project, we aim to  investigate  HA  MW  as  a  bioindicator  of  outcomes  for patients presenting with similar trauma severities.\nThe student who joins our team will learn and/or perform one or more of the following activities:\nBiochemical extraction of hyaluronan from physiological samples\nMolecular detection with the solid-state nanopore platform\nData analysis & reporting\nAdam Hall, PhD\nAssociate Professor, Biomedical Engineering VT-WFU School of Biomedical Engineering and Sciences Wake Forest University School of Medicine 575 N Patterson Ave.\nWinston-Salem, NC 27101\nhttps://thehalllab.org\nle\nAccelerometer\nGyroscope\nEMG\nActivity\nAnalysis\nWake Forest University 10I Modules Gait\nSchool of Medicine\nPostural\nProject 12 - Summer 2026\nBalance and Mobility Phenotypes of Fall Risk in Persons with Multiple Sclerosis\nThis  project  will  leverage  digital  health  technologies  (i.e.,  wearables,  mobile  apps)  and  AIbased informatics to identify potential biomechanical, physiological, and behavioral markers of fall risk in persons with multiple sclerosis (PwMS).\nFalls are a significant healthcare problem without a clear solution. Fifty percent of PwMS will fall in any three-month period with nearly half of those falls resulting in injury. Techniques that can  detect  when  a  PwMS  is  at  risk  for  falling  could  enable  the  development  of  new preventative interventions. We have collected multimodal wearable sensor data during daily life from more than 50 PwMS, capturing thousands of balance challenging activities that could be used to detect fall risk. We aim to explore how these data can be used to inform AI-based phenotypes of fall risk.\nThe student will: 1) review literature  2)  manage  thousands of daily life observations of balance challenging activities, and 3) leverage machine learning and statistical analysis techniques  to  identify  indicators of fall risk\nRyan McGinnis, PhD\nAssociate Professor Department of Biomedical Engineering Center for Remote Health Monitoring Wake Forest University School of Medicine\nWake Forest University\nSchool of Medicine\nProject 13 - Summer 2026\nDigital Health Measures of Postpartum PTSD\nThis  project  will  leverage  digital  health  technologies  (i.e.,  wearables,  mobile  apps)  and  AIbased informatics to identify potential biomechanical, physiological, and behavioral markers of post-traumatic stress disorder (PTSD).\n‚Ä¢BioStampRi\nOne in 15 pregnancies result in postpartum PTSD, which has direct bearing on child bonding and familial relationships.  Early  postpartum  is  a  sensitive  period  for risk to transmit from one generation to the next, and early intervention  could  improve  child  outcomes.  We  need destigmatized  approaches  to  alert  new  mothers  about PTSD symptoms and get them directed to care early, when intervention  can  make  the  largest  impact  on  them  and their maternal-infant bonding.\nThe student will: 1) review literature 2) help to collect and manage  data  from  a  pilot  cohort  of  postpartum  women, and  3)  leverage  machine  learning  to  identify  potential predictors of PTSD.\nRyan McGinnis, PhD\nAssociate Professor Department of Biomedical Engineering Center for Remote Health Monitoring Wake Forest University School of Medicine\nEllen McGinnis, PhD Assistant Professor Division of Public Health Sciences Center for Remote Health Monitoring Wake Forest University School of Medicine\nWake Forest University\nSchool of Medicine\nProject 14 - Summer 2026\nPredicting Panic Attacks in the Wild\nThis  project  will  leverage  digital  health  technologies  (i.e.,  wearables,  mobile  apps)  and  AIbased informatics to identify potential biomechanical, physiological, and behavioral markers of panic attacks.\nOne  in  10  people  have  experienced  a  panic  attack,  a debilitating psycho-physiological state wherein people experience  heart  palpitations,  shortness  of  breath,  and feel  out  of  control  of  their  own  bodies.  We  have  daily Apple Watch data on 90 individuals who regularly suffer from  panic  attacks.  We  will  develop  models  to  predict when panics attacks will occur to ultimately inform digital interventions to warn folks and engage them in prevention strategies.\nThe student will: 1) review literature 2) manage data from a  study  including  more  than  300  panic  attacks,  and  3) leverage  machine  learning  to  identify  predictors  of  nextday panic attacks.\nRyan McGinnis, PhD\nAssociate Professor Department of Biomedical Engineering Center for Remote Health Monitoring Wake Forest University School of Medicine\nEllen McGinnis, PhD\nAssistant Professor Division of Public Health Sciences Center for Remote Health Monitoring Wake Forest University School of Medicine\nWake Forest University School of Medicine ChAMP\nProject 15 - Summer 2026\nDetecting Anxiety and Depression in Young Children\nThis  project  will  leverage  digital  health  technologies  (i.e.,  wearables,  mobile  apps)  and  AIbased informatics to identify potential biomechanical, physiological, and behavioral markers of anxiety and depression in young children.\nIt  has  just  been  recommended  that children  be screened  for anxiety at pediatric  well visits. However, we currently do not have brief, accurate, objective screening tools to detect mental health disorders in young children. We have multimodal wearable sensor data during 3 brief laboratory tasks from 100 preschoolers with and without mental health diagnoses. We aim to develop models to detect disorders from sensor data and to examine parent and child factors that may moderate accuracy.\nThe  student  will:  1)  review  literature  2) manage  data  from  a  100-child  study  3) leverage machine learning to identify indicators  of  diagnoses  and  4)  conduct statistical  tests  to  identify  survey  and  IQ data that may moderate models\nRyan McGinnis, PhD\nAssociate Professor Department of Biomedical Engineering Center for Remote Health Monitoring Wake Forest University School of Medicine\nEllen McGinnis, PhD Assistant Professor Division of Public Health Sciences Center for Remote Health Monitoring Wake Forest University School of Medicine\nd\n7\nShoulder Force\nWake Forest University School of Medicine\nProject 16 - Summer 2026\nUnderstanding Pitching Efficiency\nBaseball  throwing  and  pitching  is  a  multifaceted,  intricate  movement  pattern  that  results  in  high forces  and  torques  throughout  the  body.  During  the  pitching  motion,  the  body  is  considered  a kinetic chain. The lower extremities generate force that is transferred through the trunk, arm, and ultimately to the hand to propel the baseball. Disruption or inefficiency within this chain increases arm stress and injury risk. It is well known that pitching velocity is related to arm stress. Therefore, the  faster  a  pitcher  throws  the  greater  their  risk  of  injury.  However,  there  are  also  pitching biomechanics and other variables that influence arm stress, pitch velocity, and ball metrics. The goal of  the  Wake  Forest  Pitching  Laboratory  is  to  find  this  balance  between  minimized  injury  risk  and maximized performance -deemed pitching efficiency.\nThe  student  will:  1)  review  literature  on pitching biomechanics 2) collect 3D motion capture data of baseball pitchers, and 3) analyze the influence of kinematics, fatigue, strength, and/or functional movement  on  arm  kinetics,  ball  velocity, and  ball  metrics. The  student  will  apply skills they learn in human subjects' research, experimental design, data collection  and  processing,  biomechanics and  human  movement, and statistical analysis to better understand pitching efficiency.\nKristen Nicholson, PhD\nAssociate Professor, Orthopedic Surgery Wake Forest Baptist Health Medical Center Boulevard Winston-Salem, NC 27157\n2S\n/e\n1\nWake Forest University\nSchool of Medicine\nProject 17 - Summer 2026\nCrash Injury Research and Engineering Network (CIREN)\nCIREN  is  a  research  catalyst  that  can  be  used  to  conduct  a  wide  range  of  motor  vehicle trauma studies.  It has been an ongoing project at WFUBMC since 2005.\nThe student will: 1) conduct detailed investigations of real-world motor vehicle crashes and determine mechanism and causation of occupant injuries to improve prevention, mitigation, and treatment of motor vehicle crashes, 2) collaborate and work closely with a broad range of medical specialties, including biomedical engineers, crash investigators,  radiologists,  orthopedic  surgeons, and  trauma  surgeons,  and  3)  conduct  finite element (FE) modeling reconstructions of CIREN crashes  using  the  simplified  GHBMC  human body model of a simplified vehicle model providing kinematic visualizations and injury analyses to supplement our investigations.\nJoel Stitzel, PhD\nProfessor & Chair, Biomedical Engineering Program Leader & Director, WFU Campus VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101 www.CIB.vt.edu\n2S\n/e\n1\nDriver FE Model\nWake Forest University\nSchool of Medicine\nFE Simulation for\nDriver Safety Optimization\nProject 18 - Summer 2026\nHead Impact Exposure Quantification and Mitigation in Motorsports\nExample On-Track Impacts\nThe  Pilot  testing  of  individualized  mouthpiece  deployment  in  motorsports  involving  injury risk assessment for the optimization of safety measures\n-1540\nThe  student  will: 1)  conduct  analysis  to quantify environmental and crash head kinematics, 2) utilize finite element  (FE) modeling for injury risk assessment for drivers in crash scenarios, and, 3) FE simulation to optimize safety measures and driver comfort.\nJoel Stitzel, PhD\nProfessor & Chair, Biomedical Engineering Program Leader & Director, WFU Campus VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101 www.CIB.vt.edu\n2S\n/e\n1\nAcce e ration g\n40\nWake Forest University\nSchool of Medicine\n1111\nProject 19 - Summer 2026\n40\nSubconcussive Head Impact Analysis using Instrumented Mouthpiece Data\nSensor technology offers researchers and consumers the ability to collect head impact data in  the  real-world;  however,  the  accuracy  of  such  sensors  has  been  limited.  This  project involves development, testing, and field deployment of a novel instrumented mouthpiece in contact sports (e.g. football, gymnastics, soccer, hockey) and everyday activities (e.g. sitting, running).\nThe  student  will:  1)  review  literature  on  head kinematics  in  athletic  and  everyday  activities, and 2) work on a project to evaluate kinematic data collected from the mouthpiece. The student  will  apply  skills  they  learn  in  human subjects'  research,  experimental  testing,  data collection and  processing,  statistical analysis, and  FE  modeling  with  a  brain  model  to  derive conclusions and a better understanding of head kinematics  and  TBI  risk  in  sports  and  everyday activities.\nJoel Stitzel, PhD\nProfessor & Chair, Biomedical Engineering Program Leader & Director, WFU Campus VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101 www.CIB.vt.edu\nWake Forest University\nSchool of Medicine\nProject 20 - Summer 2026\nEvidence-Based Intervention for Improved Head Impact Safety in Youth Sports\nDue  to  rising  concern  of  head  impact  exposure  and  concussion  in  the  21  million  children involved in team sports, this project aims to examine the sub-concussive and concussive head impact exposure in adolescent athletes instrumented with mouthpiece sensors and evaluate the effectiveness of evidence-based intervention programs in youth sports.\nThe  student  will:  1)  review  literature  focused  on cumulative exposure of sub-concussive and concussive  head  impacts  and  factors  influencing exposure  (e.g.  coaching  techniques;  practice  and game guidelines/rules; community-based interventions;  athlete  age,  size,  experience,  and position), and 2) design a hypothesis-driven experiment  to  examine  metrics  of  head  impact exposure using on-field video analysis, biomechanical data processing, and statistical approaches  learned  from  mentored  training.  The student will directly contribute to the  broader research goal of reducing sub-concussive and concussive head impact exposure to improve sport safety in adolescents\nJillian Urban, PhD, MPH\nAssociate Professor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nhttp://www.wakehealth.edu/CIB/CIB-People.htm\ny in amic\nst be may\nman suit\n‚Ä¢ can\n5\n, the jury\nch as shed\ndels asks\nNeck & Lumbar Spine Injury Risk Curve Development for Spaceflight Applications\nInjury prediction and prevention in domains analogous to spaceflight dynamic events commonly rely on the use of anthropomorphic  test  devices  (ATD),  also  known  as  crash  test dummies.  While  ATDs  have  been  effective  in  reducing  injury  in several domains, their use is limited in spaceflight as the dynamic events often involve the use of a seat or space suit that may not be compatible with the ATDs, and the dynamic events themselves may not be reproducible in a laboratory setting. Finite element human body models, on the other hand, can be outfitted with a space suit and fit  into  any  seat  design  that  may  be used. These  models can then predict the loads, accelerations, etc., of the body during the dynamic phases  of  flight.  However,  the  acceptable  level  of  injury risk in spaceflight is much lower than in analogous domains such as the automotive industry. There are currently no established thresholds for which loads on these human body models correspond to these lower levels of injury probability. These tasks seek to identify these thresholds, also known as injury assessment reference values (IARVs), for the neck and lumbar spine.\nschool.wakehealth.edu/faculty /d/karan-shamrao-devane\nAssistant Professor, Biomedical Engineering Karan Devane, PhD\nVT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nAshley Weaver, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nAshley Anne Weaver, PhD | Wake Forest University School of Medicine\nWake Forest University\nSchool of Medicine V\nK\n5\nProject 21 - Summer 2026\nCS\n2S\n1\nle\nHealthy Male\nWake Forest University\nSchool of Medicine\nProject 22 - Summer 2026\nMale with Diabetes &\nHigh-Resolution Peripheral Quantitative Computed Tomography (HR-pQCT) Scanning in Clinical Trial Interventions\nThe XtremeCT II HR-pQCT scanner provides highly specialized CT  scans  at  the  distal  radius  and  tibia.  These  images  can  be used to quantify changes in volumetric bone mineral density (BMD)  as  well  as  structural  changes  by  providing  detailed resolution of the bone microarchitecture.\nThese data are being used by our group in the clinical setting as part of interventional trials designed to evaluate the outcome of varying  weight  loss  modalities  (dietary,  exercise,  surgical)  on metrics  of  bone  health.  The  ability  to  see  microarchitecture remodeling  may  lead  to  an  increased  understanding  of  how bones  are  affected  by  weight  loss,  particularly  among  older adults.\nThe  student  will:  develop  HR-pQCT  scanning  and  analysis protocols, assist with HR-pQCT scanning of participants, and analyze HR-pQCT scan to extract bone microstructure properties (e.g., trabecular spacing, cortical porosity, trabecular and cortical BMD, finite element estimated failure load and bone stiffness) to explore how clinical trial interventions alter the skeleton.\nAshley Weaver, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics School of Biomedical Engineering and Sciences\n575 N. Patterson Ave Winston-Salem, NC 27101\nAshley Anne Weaver, PhD | Wake Forest University School of Medicine\ne\nCS\n2S\n1\nle\nMuscle CSA: 223 cm?\nIntermuscular Fat: 8%\nRadiomic Textures\nMuscle CS.A: 174 cm?\nIntennuscular Fat: 14%\nMuscle Quality/Radiomics Features and Muscle-Bone Crosstalk\nLoss of muscle mass and strength can lead to mobility disability and increase risk of osteoporosis and fracture  as  muscle  acts  both  mechanically  and  biochemically  on  bone.  We  are  conducting  studies utilizing computed tomography (CT) and magnetic resonance (MR) imaging to assess muscle changes with  weight  loss  (diet/exercise-based  or  bariatric  surgery),  disease  (e.g.  myotonic  dystrophy;  heart failure),  or  normal  aging.  We  apply  automated  machine-learning  and  semi-automated  methods  to assess changes in muscle area, volume, quality, and intermuscular fat in CT and MR scans.\nWe  also  use  automated  radiomics  analysis  to extract high-dimensional muscle quality measures, such as uniformity, heterogeneity, randomness,  and  repetitive  patterns  from  CT. These  muscle  properties  can  be  correlated  to bone  mineral  density  and  bone  strength,  which we  derive  from  imaging.  These  analyses  assess effectiveness of interventions, characterize mechanisms of disease, identify therapeutic targets, and will help establish imaging biomarkers to predict musculoskeletal decline.\nThe  student  on  this  project  will  be  trained  in image segmentation and pipelines for quantifying  muscle  properties  from  radiology. The student will examine muscle quality/radiomics  features  in  a  human  subject population and explore how these features are affected by a clinical trial intervention or disease such as myotonic dystrophy.\nMyotonic Dystrophy\nAshley Weaver, PhD\nProfessor, Biomedical Engineering VT-WFU Center for Injury Biomechanics\nSchool of Biomedical Engineering and Sciences 575 N. Patterson Ave\nWinston-Salem, NC 27101 Ashley Anne Weaver, PhD | Wake Forest University School of Medicine\nRadiomic Textures\nWake Forest University School of Medicine Muscle CSA: 102 cm? Internuscular Fat: 19%\nMuntonis Nuctunnhy\nProject 23 - Summer 2026\neS\n1\nEstimated myocardial stiffness\nWake Forest University time\nSchool of Medicine Imaging time series\nCine CMR\nCancer treatment-related cardiotoxicity\nLeft ventricular biomechanical model\nthroughout diastole\nProject 24 - Summer 2026\ndeformation\nPredicting Cancer Treatment-Related Cardiotoxicity by Imaging Cardiac Mechanical Stiffness\nCancer treatment-related cardiotoxicity is a significant concern for cancer survivors. Increased survival rates along with a younger  demographic  shift  makes  patient  survivorship issues, particularly cardiovascular disease, a forefront of clinical concern in an important patient group with decades of life  to  protect.  Cardiotoxicity  concerns  limit  therapeutic  options  and  offset  expected  therapeutic benefits. Current clinical detection  paradigms are based on semi-quantitative and subjective assessments that are only able to detect late-stage irreversible cardiac decline. There is a compelling need for new methods to assess early cardiac dysfunction to allow for interventional opportunities to minimize  cancer  therapy-induced  cardiotoxicity  while  maximizing  cancer  treatment  effect.  We  have recently  shown  the  development  of  novel  myocardial  mechanical  stiffness  phenotyping  tools.  This project  seeks  to  further  develop  and  optimize  biomechanical  model-embedded  cardiovascular magnetic resonance imaging (CMR) assessment of myocardial mechanical elasticity to accurately and non-invasively detect cancer treatment-related changes in left ventricular stiffness as an early indicator of cardiac dysfunction to inform therapeutic management strategies for breast cancer patients prior to irreversible cardiovascular damage.\nThe student will gain experience with medical image processing (segmentation, registration) and biophysical finite element modeling based on  MRI  data.  The  student  will  develop  and deploy  computational  analysis  pipelines  and contribute to the development of computational model-based image analysis methodologies to guide interventional therapy for cancer survivors.\nJared Weis, PhD\nAssociate Professor, Biomedical Engineering School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nhttp://www.weislab.org/\neS\n1\nIntestinal photoacoustic imaging (PAI) in premature infants absorption causes\nWake Forest University Light In: light pulses at specific wavelengths excite molecules\nSchool of Medicine Sound Out: optical\nthermoelastic expansion of excited molecules and\nemits ultrasound waves\nProject 25 - Summer 2026\nPhotoacoustic Imaging for Biophysical Physiological Indicators of Infant Intestinal Health and Necrotizing Enterocolitis\nNecrotizing enterocolitis (NEC) is a devastating intestinal disease affecting the most fragile premature infants, with mortality rates that persist at 20 - 40%. Accurate and conclusive early diagnosis of NEC remains  elusive, with  limited diagnostic confidence  complicating  timely  and  effective  medical management efforts to prevent disease progression to urgent surgical removal of necrotic intestine. We have recently pioneered the translational use of photoacoustic imaging for characterizing intestinal physiological  health  in  infants.  Our  current  research  goals  focus  on  developing  and  validating  these novel in vivo photoacoustic imaging methods in both humans and animal models of intestinal diseases affecting premature infants. This is an interdisciplinary research project that integrates gastrointestinal cell biology/physiology and biomedical imaging/analysis tools to explore the mechanistic underpinnings of an emerging new diagnostic imaging method for premature infant intestinal diseases\nThis project is a highly collaborative team science effort to advance a promising and translationally relevant diagnostic imaging tool with collaborators across the departments/sections of Biomedical  Engineering,  Regenerative  Medicine, Neonatology, Pediatric Surgery, Pediatric Radiology, Comparative Pathology, and Biostatistics.  The  student  will  gain  experience with ultrasound and photoacoustic image processing  and  histopathological  tissue  staining techniques used for validation of the cellular and molecular origins of changes in imaging signatures.\nJared Weis, PhD\nAssociate Professor, Biomedical Engineering School of Biomedical Engineering and Sciences 575 N. Patterson Ave Winston-Salem, NC 27101\nhttp://www.weislab.org/\n70-\n65\n601\nVolume/Surface Area\n50-\nWake Forest University Anterior\nSchool of Medicine\nAnterior\nVivarium Control\nPosterior\nHU - FEMALES\nFLIGHT\nPosterion\nHLU - MALES\nProject 26 - Summer 2026\n55-\nThe Mouse Housing Unit-8 Mission to the International Space Station: Prevention of Skeletal Complications\nLoss of bone, cartilage, and muscle during periods of microgravity in space serves as a challenge to astronaut health during and after the mission. Our previous spaceflight data (from the International Space Station and Space Shuttle) identified damage to soft (cartilage, menisci) and hard (bone) joint tissues.  Our  group  is  again  part  of  a  team  of  investigators  examining  spaceflight  affects  on musculoskeletal health. Our team is examining if artificial gravity and/or spaceflight-relevant radiation exposure can protects against spaceflight environment-induced damage to bone and joint tissues.\nThis spaceflight mission for our REU team member involved sending mice to the International Space Station  in  March,  2023,  and  also  that  were  exposed  to  spaceflight  radiation  at  the  NASA  Space Radiation Lab. For the spaceflight study, we exposed the mice to continuous artificial gravity as via centrifugation aboard the ISS, as part of a joint study between NASA and the Japanese Space Agency. Mice received different gravitational levels, including near 0G, 0.67G, 0.33G (Martian), and 1G, to see if  artificial  gravity  could  project  against  skeletal  damage.  Likewise,  rodents  were  exposed  to spaceflight radiation and / or simulated microgravity.\nThe  REU  student  will have  the opportunity to perform skeletal-related analyses across tissues. We are  interested  in  a  team  member  who  can  help establish  mechanical  testing  (e.g.,  using  AFM  or other approaches)  to  identify whether  cartilage mechanics are altered during/after spaceflight, with/without artificial gravity, and/or after exposure to spaceflight radiation, although we can be flexible with engineering and biologic approaches.\nJeffrey Willey, PhD\nProfessor, Radiation Oncology Wake Forest University School of Medicine Medical Center Boulevard Winston-Salem, NC  27157\nhttp://www.wakehealth.edu/Faculty/Willey-Jeffrey-Scott.htm\nGround Control\nAnterior\nPosterion\nRR9\n60-\n55-\nIzation algorithms for real w ction.\n1: 6\nElemance er\nC\nC\nWake Forest University\nSchool of Medicine\nProject 27 - Summer 2026\nRapid Design and Optimization of Personal Protective Equipment to Mitigate Warfighter Injury Risk\nBackground: The modern United States warfighter is equipped with a sophisticated suite of personal protective equipment  (PPE).  However,  the  complexity  of  modern  PPE  and  the  variety  of  design  criteria,  certification requirements, and performance considerations require a labor intensive and experimentally demanding design process. Adding to these difficulties are the lack of suitable and accessible human surrogates for translating the effectiveness of PPE in testing to prediction of real-world performance for military personnel in theater. Advanced digital engineering tools are poised to fill gaps in the current PPE design process and facilitate both expedited and more comprehensive design analyses. One key tool available in the digital design space to serve this purpose is the computational Finite Element (FE) Human Body Model (HBM). Another key tool is probabilistic methodologies to facilitate  uncertainty quantification and optimization. The objective of this project is to develop a digital design tool  capable  of  rapid  design  exploration  of  PPE  through  the  coupling  of  state-of-the-art  HBMs  with  advanced probabilistic and optimization techniques. The proposed software solution will provide manufacturers with a tool to  accelerate  the  PPE  design  cycle  while  also  making  performance  more  focused  on  relevant  real  world  injury reduction.\nStudent Activities:\nThe student will gain experience in‚Ä¶\nDeveloping desktop applications, including interactive 3D visualizations of human body models and PPE designs\nPost -processing finite element simulations of human body models and calculating relevant biomechanical metrics for injury risk analysis\nUtilizing machine learning models and optimization algorithms for real world PPE applications\nLocation:\nTanner Filben, PhD\nResearch Engineer Elemance, LLC Winston-Salem, NC\nZach Hostetler, PhD\nSenior Engineer Elemance, LLC Winston-Salem, NC\n2 o'clock to 3 o'clock\nR\nRV\nAI\nTricusple zaive RA\nLV\nST\nLA\nWake Forest University\nSchool of Medicine\nbutral valve\nProject 28 - Summer 2026\nMedical Image Generation from Physiological Signals\nMedical imaging modalities, such as echocardiogram, computed tomography, or cardiac magnetic resonance, typically forms the gold standard diagnostics for most cardiovascular diseases. However, such images are associated with high cost  and  low  accessibility  limiting their  utility  in  cardiovascular  diseases screening purposes. On the other hand, electrocardiogram is significantly more frequently  recorded  and  widely  accessible,  yet,  it  is  not  satisfactory  for  gold standard  diagnosis  of  most  diseases.  Hence,  there  is  a  need  for  artificial intelligence  tools  to  convert  information  in  ECG  signals  into  rich  information gathered from these cardiac imaging modalities.\nThis research effort will be in the Department of Cardiovascular Medicine and the Center for Artificial Intelligence. The intern will be provided with data and computational  resources  to  develop  AI  models  that  can  1)  estimate  imaging parameters from ECG and 2) to construct images from ECG signals.\nOguz Akbilgic, PhD\nProfessor, Artificial Intelligence Department of Cardiovascular Medicine Wake Forest University School of Medicine 486 N. Patterson Ave\nWinston-Salem, NC 27101\noguz.akbilgic@advocatehealth.org https://www.linkedin.com/in/oguz-akbilgic-a385ba37/\nase le\n7\ncolisuel\nMetabolomics\nGenetics\nWake Forest University\nSchool of Medicine\nProject 29 - Summer 2026\nAssociation Analysis\nInvestigating the Genetic Architecture of the Metabolome to Provide Insight into Cardiometabolic Disease Risk\nMetabolomic profiles  are  highly  informative  of  an individual's functional  state  and  capture  the interaction  of  cellular  processes  and  environmental  exposures  to  promote  disease.  Highthroughput profiling has implicated multiple metabolites in cardiometabolic disease risk, e.g. type 2  diabetes  (T2D)  and  obesity.  Minority  populations  experience  a  disproportionate  burden  of cardiometabolic  disease;  however,  studies  in  these  populations  have  been  few  in  number  and limited in scope.\nMetabolomics\nGenetics\nLinkage Analysis\nAssociation Analysis\nCardiometabolic Disease\nGoal :  Provide  a  comprehensive  survey  of  the genetic architecture of untargeted metabolomics data. Data include 1274 plasma metabolites with  genetic  data  drawn  from genome-wide array, whole exome sequencing and whole genome sequencing. Methods to be incorporated include family-based linkage analysis  and  variance  components  models  to test for association.\nExpectation: The student working on this project will be trained on the implementation of statistical analysis packages  relevant  for linkage,  association  and  plotting  of  results. Results will be contextualized using the relevant literature for implication in cardiometabolic disease states. Students interested in genetics, statistics and cardiometabolic disease should consider applying.\nNicholette D. (Palmer) Allred, PhD\nProfessor, Biochemistry Wake Forest University School of Medicine Atrium Health Wake Forest Baptist Medical Center Boulevard Winston-Salem, NC 27157\ne\nE\ne\nb\nLobar Consolidation\nAtelectasis\nFine Nodular\nWake Forest University\nSchool of Medicine Multifocal ill defined\nDiffuse Consolidation\nFine Reticular Interstitial\nSolitary Pulmonary Nodule\nCoarse Reticular Interstitial\nProject 30 - Summer 2026\nAnomaly Detection in Lung X-rays\nThe timely and accurate diagnosis of lung abnormalities from chest X-rays is a critical factor in  patient  outcomes.  Chest  X-rays  are  one  of  the  most  common  diagnostic  imaging  tests, capable of revealing a wide range of conditions including cancer, pneumonia, and collapsed lungs. However, the interpretation of these images can be challenging and subject to human error,  with  missed  lung  nodules  being  a  predominant  cause  of  malpractice  claims  in  chest imaging.\nDeep learning has emerged as a powerful tool in medical image analysis, with the potential to improve the accuracy and efficiency of diagnoses. This project aims to develop a robust and interpretable  deep  learning  framework  to  automatically  detect and classify various anomalies in chest X-ray images. By automating  this  detection  process,  we  can  create  a  low-cost, scalable  tool  to  assist  radiologists,  prioritize  urgent  cases,  and ultimately improve patient care.\nLearning Objectives:\nGain hands-on experience with deep learning for medical image analysis.\nLearn and apply computer vision techniques on lung pathologies.\nWork with large-scale, real-world chest X-ray datasets and address challenges such as class imbalance and data variability.\nDevelop skills in model validation and interpretation in a clinical context.\nExpectation\n: Good programming skills in python, familiarity with\nPyTorch and basic knowledge of Machine learning/Deep learning.\nMetin Gurcan, Ph.D.\nSenior Associate Dean for Artificial Intelligence\nDirector, Center for Artificial Intelligence Research (CAIR) Professor, Department of Internal Medicine, Pathology, BME Wake Forest University School of Medicine https://school.wakehealth.edu/research/labs/clinical-image-analysis-lab\ne\nE\ne\nb\nWake Forest University\nSchool of Medicine\nProject 31 - Summer 2026\nOtoscopy Assistant Diagnosis System with Integrated Classification and Out-of-Distribution Detection\nEar diseases are highly prevalent worldwide and often require expert evaluation of otoscopic images  and  videos  for  accurate  diagnosis.  However,  variations  in  image  quality,  patient anatomy,  and  disease  presentation  make  automated  analysis  challenging.  This  project focuses on developing an advanced assistant diagnostic system for otoscopy by combining disease classification with out-of-distribution (OOD) detection.\nThe classification component aims to train state-of-the-art deep learning models to accurately identify common otologic conditions such as effusion, perforation, and infection. Simultaneously, the OOD detection module will identify samples that fall outside the distribution of the training dataset, such as images of rare diseases, poor-quality frames, or ambiguous cases that  are  difficult even  for  clinicians  to  diagnose.  This  dual approach ensures that the system can not only provide reliable predictions for known conditions but also flag uncertain or novel cases  for  further  expert  review,  thereby  increasing  safety  and trustworthiness in clinical applications.\nLearning Objectives:\nGain hands-on experience with deep learning for medical image\nNormal\nPerforation\nand video analysis. Learn techniques for out-of-distribution detection, uncertainty quantification, and trustworthy AI. Work with real-world otoscopy datasets and experience challenges such as image quality variability and dataset imbalance.\nExpectation : Good programming skills in python, familiarity with PyTorch or TensorFlow and basic knowledge of Machine learning.\nMetin Gurcan, Ph.D.\nSenior Associate Dean for Artificial Intelligence Director, Center for Artificial Intelligence Research (CAIR) Professor, Department of Internal Medicine, Pathology, BME Wake Forest University School of Medicine https://school.wakehealth.edu/research/labs/clinical-image-analysis-lab\nLow quality (normal)\nUdsIC\nryloren ana basic\nWake Forest University School of Medicine –£ –£ 4 y 11\nProject 32 - Summer 2026\nStructuring and Standardizing Patient Discharge Notes\nPatient discharge summaries and notes often vary depending on the hospital, region, and the individual physician's documentation style. These differences can make it difficult to quickly capture  key  information  when  a  patient  is  transferred  to  another  department  or  hospital. This  project  aims  to  create  a  more  systematic,  standardized  structure  for  patient  notes  to ensure critical information is easier to find and interpret across different settings.\nSignificance\nInconsistent  documentation  formats  across  hospitals and  regions  can  lead  to  missed  critical  information, delayed care, and unnecessary repetition of tests. By standardizing the structure of discharge and anamnesis notes, this project will improve continuity of  care,  prevent  oversight  of  life-saving  details,  and make patient follow-up more systematic and efficient.\nLearning Objectives:\nTo  develop  and  validate  a  Natural  Language  Processing  (NLP)  model  capable  of  accurately identifying and extracting key clinical entities from unstructured, free-text discharge notes. These entities include diagnoses, medications, procedures, allergies, lab results, and followup plans To evaluate the effectiveness of the AI-generated standardized notes by measuring reductions in documentation time for physicians and improvements in information retrieval accuracy by receiving clinicians. To assess the impact of the standardized notes on patient safety metrics, such as medication errors and hospital readmission rates.\nExpectation :  Good  programming  skills  in  python,  familiarity  with  PyTorch  and  basic knowledge of Machine learning/Deep learning.\nMetin Gurcan, Ph.D.\nSenior Associate Dean for Artificial Intelligence Director, Center for Artificial Intelligence Research (CAIR) Professor, Department of Internal Medicine, Pathology, BME Wake Forest University School of Medicine https://school.wakehealth.edu/research/labs/clinical-image-analysis-lab\ne\nE\ne\nb\ne\nE\ne\nb\nWake Forest University\nSchool of Medicine\nProject 33 - Summer 2026\nPredicting Breast Cancer Recurrence From H&E-Stained Whole Slide Images\nThe risk of disease recurrence is a critical factor in determining the course of treatment for breast  cancer  patients.  While  genomic  assays  like  Oncotype  DX  provide  recurrence  risk scores,  they  are  expensive  and  not  universally  available.  Histopathological  examination  of H&E-stained tissue slides remains the cornerstone of diagnosis, and these images contain a wealth of morphological information that correlates with tumor aggression and, ultimately, recurrence risk.\nHowever, a pathologist's visual assessment of recurrence risk is inherently subjective and based on integrating a complex set of features like tumor grade, mitotic activity, and the nature of the tumor-immune interface. This project aims to develop a robust and interpretable deep learning framework to objectively predict breast  cancer  recurrence  directly  from  standard  H&E-stained Whole  Slide  Images  (WSIs).  By  automating  this  prediction,  we can create a low-cost, scalable tool to augment clinical decisionmaking and better stratify patients.\nLearning Objectives:\nGain hands-on experience with deep learning for medical image analysis. Learn techniques for object detection, segmentation, and multi-instance learning. Work with real-world histopathology datasets and experience challenges such as image stain variability and dataset imbalance.\nExpectation : Good programming skills in python, familiarity with PyTorch and basic knowledge of Machine learning/Deep learning.\nMetin Gurcan, Ph.D.\nSenior Associate Dean for Artificial Intelligence Director, Center for Artificial Intelligence Research (CAIR) Professor, Department of Internal Medicine, Pathology, BME Wake Forest University School of Medicine https://school.wakehealth.edu/research/labs/clinical-image-analysis-lab\nBreast WSI Tiles\ne\nE\ne\nb\nWake Forest University\nSchool of Medicine\nProject 34 - Summer 2026\nNuclei and Tissue Segmentation in Whole Slide Histology Images\nPathology slides contain a wealth of information that is essential for accurate diagnosis. This project focuses on developing a model that can automatically detect whether a slide contains pathological findings, even spotting abnormalities that the human eye might miss. In places where pathologists are not available, diagnosis can be delayed, which affects treatment decisions and patient outcomes. This project aims to support healthcare teams by providing a reliable, AI-powered screening tool that speeds up the process and helps ensure no critical findings are overlooked.\nOur Approach:\nWe will use a dataset of H&E-stained Whole Slide Images (WSIs) and apply deep learning based segmentation algorithms to identify nuclei and tissue regions. These segmented regions will then be analyzed with classification models to determine whether the slide shows any pathological features.\nLearning Objectives: Key learning objectives include implementing\nsegmentation models to identify nuclei and tissue regions and developing classification models to detect pathological features. The primary expectation is to build, train, and quantitatively evaluate a complete AI pipeline for automated slide analysis, culminating in a functional and well-documented system.\nExpectation: The participant is expected to gain hands-on experience in digital pathology by applying deep learning algorithms to H&E-stained Whole Slide Images (WSIs).\nMetin Gurcan, Ph.D.\nSenior Associate Dean for Artificial Intelligence Director, Center for Artificial Intelligence Research (CAIR) Professor, Department of Internal Medicine, Pathology, BME Wake Forest University School of Medicine https://school.wakehealth.edu/research/labs/clinical-image-analysis-lab\nlea uL models by spatial perspecuives of the Input adla (clu).\nr\neS.\nDL\n12 Lead ECG\nWake Forest University 64.3.2 64,3,2 16.3,1 32311 32,1,2 64,1,2\nSchool of Medicine\nInput\nConviD\nBatch\nNormalization\nLeaky RELU\nAdd\nMax Pooling\nDropout\nFlatten\nProject 35 - Summer 2026\nNovel Deep learning Algorithms and Explainable AI on ECG\nBackground : In Deep Learning (DL), there are various types of layers that are specialized for specific tasks. For example, the convolutional layers slides over the input (image or its representation) spatially to extract features. However, there is still a gap in the literature to design a DL layer for ECG specific. And the black-box side of the DL is still an open-research area, specifically for ECG based models.\nGoal : The goal of this project is to build ECG inputted novel DL algorithms (layers, activation functions, or architecture based) for prediction/classification of cardiovascular diseases. And the other goal is to uncover the black-box side of ECG fed DL models by spatial perspectives of the input data (ECG).\nExpectation : The student in this project will is expected to have Python programming skill and work on 1) building novel DL algorithms fed by ECG 2) design infrastructure to uncover the black-box of ECG fed DL models, 3) compare results with state-of-the art algorithms\nIbrahim Karabayir, PhD\nAssistant Professor, Wake Forest University Health Science Internal Medicine, Section on Cardiovascular Medicine Center for Artificial Intelligence Research (CAIR) Wake Forest University School of Medicine\nS\nal te\nWake Forest University\nSchool of Medicine\nT G\nC√ÉA\nProject 36 - Summer 2026\nLanguage-based AI Model on Genomic Data to Understand and Predict risk of Alzheimer Disease and Multimorbidity\nBackground : Our Genomes such as DNA encode molecular-level information about disease risk. Traditional methods using polygenic risk scores only explore the risk of a single disease for every single gene, omitting the high-level genetic interaction of genomic sequences that are associated with multiple diseases. The recent development of the Natural Language Processing (NLP) model has shown success in the comprehension of high-level context in sequence data such as sentences. Similarly, NLP models can also be applied to genomic sequences to extract high-level genotype information for multiple related diseases. However, studies in this field is still limited despite the strong potential.\nGoal : The goal of this project is to 1) develop novel NLP-based deep learning models on genomic data to predict the composite risk for multiple diseases.\nExpectation : The student in this project will be expected to have Python programming skills and work on 1) developing representation learning models to extract high-level genomic features 2) predicting multi-disease risk factors and identifying high-level genomic associations.\nDa Ma, PhD\nAssociate Professor,\nGerontology and Geriatric Medicine Center for Artificial Intelligence Research (CAIR)\nMichael Horvath, MS\nLead Programmer / Analyst, Clinical and Translational Science Institute\nAlzheimer's Disease Research Center\nWake Forest University School of Medicine https://school.wakehealth.edu/faculty/m/da-ma\nWake Forest University School of Medicine\nProject 37 - Summer 2026\nMultimodal System for Early Identification of Cardiovascular Diseases\nCardiovascular diseases (CVDs) are the leading cause of death globally. Many forms of CVDs are progressive and develop over time. Early identification and guided treatment may assist to manage the disease and reduce the burden. In this project, we will collect data from patients and analyze data to identify early signs of CVDs. We will develop a multimodal system to record different signals  such  as  temperature,  blood  pressure  and  ECGs  from  patients  and healthy subjects. We will analyze data to find abnormalities associated with CVDs.\nThe  student  will:  1)  review  literature  on vital signs analysis, 2) develop a multimodal  system,  3)  collect  data  from patients and healthy subject, and 4) analyze data to find abnormalities.\nBackground in electronic circuits, statistical analysis and hands-onexperience with electronic equipment will be essential for this project.\nMohammad Moghimi, PhD\nAssistant Professor, Department of Biomedical Engineering Center for Artificial Intelligence Research (CAIR) Center for Remote Health Monitoring Wake Forest University School of Medicine\n575 Patterson Ave, Suite 120 Winston-Salem, NC 27101\nmanagement Increase the chance or successtul treatment ana reauce the burden.\nWake Forest University In this project, we will develop a wearable patch that can be used by individuals out of clinical setting to evaluate the risk of melanoma on decolored parts of skin\nSchool of Medicine\nMedical Tape\nProject 38 - Summer 2026\nWearable Flexible Patch for Early Identification of Melanoma\nMelanoma is the most malicious type of skin cancer, and the incidence was on rise in  the  last  decades.  In  the  United  States  alone,  97,610  new  cases  of  melanoma were  diagnosed  in  2023,  and  mortality  rate  was  7,9901.  Melanoma  may  leave marks  on  skin  and  cause  cosmetic  issues  for  the  patients.  As  the  tumor  grows, melanoma  may  metastasize  and  result  in  death.  Early  identification  and  timely management increase the chance of successful treatment and reduce the burden. In this project, we will develop a wearable patch that can be used by individuals out of clinical setting to evaluate the risk of melanoma on decolored parts of skin and lesions.\nThe  student  will:  1)  review  literature  on melanoma detection, 2) optimize the flexible patch, 3) collect data from lesions, and  4)  analyze  data  from  benign  and malignant tumors.\nBackground in electronic circuits, statistical analysis and hands-onexperience with electronic equipment will be essential for this project.\nWearable patch placed on a lesions\n2 cm\nPatch\nMedical Tape\nPatient\nMohammad Moghimi, PhD\nAssistant Professor, Department of Biomedical Engineering Center for Artificial Intelligence Research (CAIR) Center for Remote Health Monitoring Wake Forest University School of Medicine\n575 Patterson Ave, Suite 120 Winston-Salem, NC 27101\nPatch and lesions.\nWake Forest University\nSchool of Medicine\nProject 39 - Summer 2026\nAI-Assisted Pre-screening for Neurological Disorders\nNeurological  disorders  (NDs)  are  the  number  one  cause  of  disability  and  the second leading cause of death globally. Evidence is emerging showing that NDs are in fact multi system syndromes affecting different aspects of patients' health and  well-being. Early diagnosis enables  access to timely intervention  and therapeutics. However, diagnosis of most NDs is challenging due to heterogeneity of disease and lack of evident physical phenotypes. The goal of this project is to use advanced artificial intelligence (AI) techniques to assist the diagnostic process and characterize the clinical risk associated with NDs.\nThe  student  will:  1)  review  literature  on prevalence and diagnosis of different neurological  disorders,  2)  evaluate  the previously trained model on a new dataset,  3)  evaluate  the  model  across various patient subgroups defined by race/ethnicity,  sex,  and  co-occurrence  of key  diagnosis.  This  data  will  inform  the development of more accurate and inclusive AI-assisted pre-screening models for neurological disorders  which  could lead  to  more  equitable  diagnosis  and health care for patients.\nArezoo Movaghar, PhD\nAssistant Professor, Department of Pediatrics Center for Artificial Intelligence Research (CAIR) Wake Forest University School of Medicine\nMeads Hall, Queen St., Medical Center Blvd. Winston-Salem, NC 27103\nAAATCATGCGCAT\nGTCAAATATACAT\nGCGCATGCGGTA.\nAAGGCTACG\n¬∞61,\nWake Forest University\nSchool of Medicine\ngIGANATATCATGCGCA!\nProject 40 - Summer 2026\nGenetic Analysis of Machine Learning-Based Rate of Aging Metrics\nUnderstanding  the  difference  between  biological  aging  and  chronological  aging  is  at  the  crux  of geroscience and our ability to target interventions that reduce disease and improve quality of life for older adults. This project is developing rate of aging (RoA) metrics using machine learning and AI-based tools across a range of non-human primate (NHP) species based on routinely collected clinical data. We will use these RoA to identify shared and species-specific patterns of biological aging across 15,000 NHPs to test if longer lifespans within and between species are associated with increased physiological disruption later in life and a slower pace of biological aging. We will then identify genetic variants that differentiate exceptionally fast and slow agers to characterize pathways mediating health and lifespan differences within and between species. This will leverage existing sequence data in >3,000 NHPs to identify  rare  and  common  genetic  variants  associated  with  lifespan,  healthspan,  and  pace  of  aging within species. This data will be used to identify the underlying biology driving differences in longevity within  and  between  species  which  will  highlight  biological  pathways  for  potential  interventions  in human patients.\nThe student will  gain  experience  in  training and  fine-tuning  neural  network  algorithms, handling large-scale datasets, and performing genetic and bioinformatics analyses. They will also learn how to perform  phylogenetic  analyses  across  nonhuman  primate  species to interpret the evolution  of  longevity  in  humans  and  the translational potential of non-human primate data.\nEllen Quillen, PhD\nAssociate Professor Department of Internal Medicine-Molecular Medicine Center for Precision Medicine Center for Artificial Intelligence Research (CAIR) Wake Forest University School of Medicine http://www.quillenlab.org/\nC\nWake Forest University\nSchool of Medicine\nProject 41 - Summer 2026\nMulti-Modal Fusion of Histopathology and Omics Data for Precision Cancer Diagnosis\nThe goal of this project is to enhance cancer diagnosis by integrating histopathology images and multiomics molecular data, which are publicly available from datasets such as The Cancer Genome Atlas (TCGA).  This  project  will  guide  students  through  the  process  of  analyzing  these  large  and  diverse datasets. Initially, the project will address the processing of gigapixel-sized whole slide images (WSIs), which are essential for assessing the morphological characteristics of cancerous tissues. Due to their enormity and complexity, WSIs  cannot be  analyzed  in  their  entirety  efficiently.  Instead,  they  will  be broken down into smaller, manageable sections known as patches. Each patch will be encoded as a vector,  creating  a  matrix  where  each  column  represents  the  embedding  for  a  patch,  and  the  entire matrix  encapsulates  the  comprehensive  information  of  the  WSI.  To  manage  and  interpret  this  vast amount  of  data  effectively,  linear  algebra  tools  such  as  various  matrix  decompositions  will  be employed to reduce the dimensionality of these matrices. Alongside the imaging data, molecular data from multi-omics sources provides deep insights into the genetic and molecular bases of cancer. This data  includes  detailed  genomic,  transcriptomic,  and  proteomic  information  that,  when  analyzed  in conjunction with WSIs, can reveal comprehensive insights into the biological behavior of tumors. The project  will  explore  how  the  integration  of  these  two  distinct  data  modalities  can  significantly transform patient diagnosis and treatment planning by providing a more nuanced understanding of the disease.\nLearning Objectives: Through this project, students will not only develop technical skills in handling and analyzing large-scale datasets using Python and its associated libraries but also deepen  their  understanding  of  the  statistical challenges in data integration. The knowledge of linear algebra will be applied to real-world scenarios,  enhancing  the students' ability to manage and interpret complex datasets.\nPrerequisites: Students interested in participating in this project should have a basic understanding of statistics and linear algebra. Additionally, proficiency in Python is important for successfully completing the project tasks.\nMostafa Rezapour, PhD\nAssistant Professor Wake Forest Institute for Regenerative Medicine (WFIRM) Center for Artificial Intelligence Research (CAIR) Wake Forest University School of Medicine 486 N. Patterson Avenue\nWinston-Salem, NC 27101\ns for correlating behavioral and microbiological datasets.\nWake Forest University\nSchool of Medicine\nProject 42 - Summer 2026\nannlicatione in animal hahavior analucic\n‚Ä¢AmI\nTAI\nvicion\nComputer Vision Analysis of Maternal Behavior in Vervet Monkeys  for Understanding Early Life Microbiome Transmission\nVervet  monkeys  serve  as  an  excellent  model  system  for  studying  maternal  investment  and  microbiome transmission due to their complex social behaviors, diverse microbiomes, and developmental patterns that are similar to human. Traditional manual coding methods for quantifying maternal behaviors  are timeintensive and subjective. The goal of this project is to develop an automated computer vision pipeline to analyze video recordings of vervet monkey mothers with their infants, quantifying maternal care behaviors and  correlating  these  patterns  with  microbiome  transmission  data.  This  will  provide  insights  into  how specific maternal behaviors influence the establishment of the gut microbiome in early life.\nThe  student  will  gain  hands-on  experience  with  computer  vision  techniques  including  object  detection, tracking algorithms, and pose estimation. They will learn to work with large video datasets, develop skills in  deep  learning  framework  implementation  and  better  understand  the  intersection  of  computational biology  and  animal  behavior  research.  The  student  will  also  develop  experience  in  data  analysis  and statistical methods for correlating behavioral and microbiological datasets.\nThe student will:\nReview literature on computer vision applications in animal behavior analysis\nDevelop and train deep learning models for automated detection and tracking of vervet monkeys in video footage\nImplement behavioral classification algorithms to identify and quantify specific infant care associated behaviors\nAnalyze correlations between automated behavioral measurements and microbiome data to identify key behaviors shaping microbial transmission\nDaniel Sprockett, PhD, MSc\nAssistant Professor, Microbiology and Immunology Wake Forest University School of Medicine Wake Forest Biotech Place 575 Patterson Ave Winston-Salem, NC 27101\nhttps://danielsprockett.github.io/\nMicrobial\nCommunities\nWake Forest University Complex Mixtures of DNA Bacterial Genomes\nSchool of Medicine\nProject 43 - Summer 2026\nAI-Enabled Metagenomic Binning: Integrating Long-Read and ShortRead Data for Improved Microbial Genome Reconstruction\nMetagenomic  sequencing allows researchers to study entire microbial communities directly from environmental samples, providing insights into microbial diversity, function, and interactions. A critical step in  metagenomics analysis is \"binning\" - the process of grouping DNA sequences that originate from the same microbial species to reconstruct individual genomes from complex mixtures. The goal of this project is to  develop  novel  AI-based  approaches  that  integrate  long-read  sequencing  data  with  short-read assemblies to improve the accuracy and completeness of metagenomic binning.\nThe  student  will  gain  experience  with  bioinformatics  data  processing,  including  handling  large-scale sequencing datasets. They will develop skills in advanced machine learning techniques, particularly in multimodal data integration and graph-based neural networks. The project provides exposure to metagenomics  analysis  pipelines  and  microbial  genomics  concepts,  as  well  as  experience  in  method development and computational benchmarking.\nThe student will:\nReview literature on current metagenomic binning methods and hybrid sequencing approaches\nDevelop and implement machine learning models that can integrate long-read and short-read data features\nDesign training and validation frameworks using existing metagenomic datasets with known ground truth\nBenchmark the new hybrid approach against existing state-of-the-art binning tools to demonstrate performance improvements.\nDaniel Sprockett, PhD, MSc\nAssistant Professor, Microbiology and Immunology Wake Forest University School of Medicine Wake Forest Biotech Place 575 Patterson Ave Winston-Salem, NC 27101\nhttps://danielsprockett.github.io/\nle le\nn\nWake Forest University\nSchool of Medicine\nProject 44 - Summer 2026\nExploring Vision and Mobility in BNET-EYE\nOlder  adults  with  poor  vision  are  at  higher  risk  for  falls  and  mobility  disability,  but  the mechanisms linking different aspects of visual function to these adverse outcomes are not wellunderstood.  Moreover,  whether  microstructural  differences  in  the  retina  or  optic  nerve  may explain relationships  between visual  and physical  function  is  not  known.  In  the  Brain  Network and Mobility (BNET)-EYE study, we are measuring performance on the expanded short physical performance  battery  (eSPPB)  and  have  collected  a  portfolio  of  traditional  and  novel  visual function metrics as well as microstructural anatomy of the optic nerve and retina using optical coherence tomography/angiography (OCT/A) in older and younger adults.\nIn  this  project,  the  student  will  1)  learn  about different  tests  of  visual  function  and  2)  learn  to analyze OCT/A microstructural ophthalmic imaging to quantify different anatomical structures  in  the  retina  and  optic  nerve.  This microstructural  data  will  allow  novel  exploration of the relationship between visual function, ophthalmic microstructure, and physical function.\nThe student will develop a hypothesis-driven investigation to analyze whether a specific visual function metric is associated with mobility performance on the eSPPB, and whether ophthalmic microstructural differences may explain this relationship.\nAtalie Thompson, MD, MPH\nAssistant Professor, Dep. of Surgical Ophthalmology\nAssistant Professor, Div. of Gerontology and Geriatric Medicine Wake Forest University School of Medicine https://school.wakehealth.edu/faculty/t/atalie-carina-thompson",
      "metadata": {
        "chunk_index": 0,
        "source_type": "attachment",
        "message_id": "19aadaf0f535cdc9",
        "from": "Abhinav Batra <ab12615@nyu.edu>",
        "to": [],
        "subject": "Test email wih different attachments",
        "date": "Sat, 22 Nov 2025 17:28:07 -0500",
        "timestamp": 1763850487,
        "token_count": 19275,
        "attachment_name": "19a2beedbec581a4_2026 BME-CAIR Research Project Descriptions.pdf",
        "attachment_type": "pdf"
      }
    },
    {
      "chunk_id": "19aadaf0f535cdc9_att_199c9706b9e3f785_Genhack-Challenge_jpg_0_dec93cff",
      "text": "WHY TO COMPETE ?\nAdvance research on the urban heat island effect\nWork with real-world climate and satellite data\nSharpen skills in data science and visualization\nNetwork with leading experts and industry partners\nGen Hack\n2025\nGENHACK 4\nMeasuring the Urban Heat Island Effects\n1 month of climate problem solving using Al, Datascience, and generative models !\nSIGN UP\nRegistration deadline November 7th\nRegistration: October 6th\nKick off : November 12th\nHackathon : November 12th to December 11th\nFONDATION\nECOLE POLYTECHNIQUE\nINSTITUT\nPOLYTECHNIQUE\nDE PARIS\nBNP PARIBAS\nThe bank for a changing world\nRiSK\nSTRESS\nTEST",
      "metadata": {
        "chunk_index": 0,
        "source_type": "attachment",
        "message_id": "19aadaf0f535cdc9",
        "from": "Abhinav Batra <ab12615@nyu.edu>",
        "to": [],
        "subject": "Test email wih different attachments",
        "date": "Sat, 22 Nov 2025 17:28:07 -0500",
        "timestamp": 1763850487,
        "token_count": 154,
        "attachment_name": "199c9706b9e3f785_Genhack-Challenge.jpg",
        "attachment_type": "jpg"
      }
    }
  ]
}